{
    "status": "ok",
    "feed": {
        "url": "https://blog.swmansion.com/feed",
        "title": "Software Mansion - Medium",
        "link": "https://blog.swmansion.com/?source=rss----e003bf129483---4",
        "author": "",
        "description": "We are a team of engineers. - Medium",
        "image": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png"
    },
    "items": [
        {
            "title": "Modular RTC Engine is our little-big revolution in video conferencing",
            "pubDate": "2022-01-03 10:52:18",
            "link": "https://blog.swmansion.com/modular-rtc-engine-is-our-little-big-revolution-in-video-conferencing-cfde806c5beb?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/cfde806c5beb",
            "author": "B\u0142a\u017cej Pierzak",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*2Dp2V9J8Ro-6VGXgAZo9eQ.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2Dp2V9J8Ro-6VGXgAZo9eQ.png\"></figure><p>There are already quite a few WebRTC SFU implementations in different programming languages. They\u2019ve got their pros and cons, but the biggest problem about them is that you need to take them as they are. If you need to do something extraordinary, like creating a custom logic, there is a lot of work you need to do. Probably you need to rewrite almost everything from the original library to finally get something that matches your requirement. But the result could still be hardly reusable.</p>\n<p>We\u2019ve made Membrane as a solution for that kind of trouble. That\u2019s why we decided on the pipeline to be the core concept of the framework. And that\u2019s why we have made it easy to create your own element for the pipeline besides the ones we provided. That modularity is the main advantage of Membrane\u2019s approach.</p>\n<p>Later when we started working on our WebRTC implementation we concentrated on implementing the SFU architecture and making things work. We encapsulated the pipeline inside RTC Engine, and we made it do nothing more, but to receive a stream from each peer and to transfer it to other peers (OK, many other things happen there, but they\u2019re less directly related to media transferring).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/631/0*3bgiXj8_DXh697lK\"></figure><p>Technically, the RTC Engine is still a pipeline, so now we decided to rebuild it and make it available to add new functionalities. What kind? You can decide for yourself. With the new architecture of the Membrane RTC Engine, we give you the possibility to arrange your SFU server however you\u00a0need.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/631/0*DHT51fKr5Clu35W5\"></figure><p>But let\u2019s talk about the basic configuration. We\u2019ve got an RTC Engine running on some machine with a basic configuration for WebRTC connections. After you establish a connection with the server it will send info to the RTC Engine about a new peer connected. RTC Engine will create a process called Endpoint (based on the specification we provide) for each connected peer. An Endpoint is a new abstraction that allows us to connect different types of I/O within the RTC Engine. In our case, it will be a WebRTC type Endpoint. Next, our Endpoint will receive from the RTC Engine the list of tracks broadcasted by other Endpoints and can subscribe to each of those.. (Or not. You may write some custom logic for that if you need it). After subscription, your Endpoint will start receiving data from the broadcaster and pass it to your\u00a0browser.</p>\n<p>Accordingly, if you start sending data, your Endpoint will send a message to the RTC Engine that it\u2019s starting broadcasting. RTC Engine will pass this message to other Endpoints, and they\u2019ll subscribe (or not) to your broadcast.</p>\n<p>So, what is so revolutionary here? Let\u2019s Imagine that you have an existing application like that\u200a\u2014\u200aa simple video conference application, and you want to record each peer video to a file. Now you can do this without changing the whole SFU application. All you need is to create a new Endpoint that will subscribe to each peer broadcast, and write it down into a file. It won\u2019t require much work, because that Endpoint is a regular Membrane Bin. One new thing is, to receive data from the other endpoints, it needs to register into the RTC Engine, and after receiving a message about currently available tracks, it needs to answer with proper subscription info. That\u2019s all. The rest is just a simple pipeline\u00a0linking:</p>\n<p>link_bin_input() |&gt; to(:encoder) |&gt; to(:file_sink)</p>\n<p>We can also create a filter Endpoint. Like in the previous example, we can subscribe to some tracks, process them and then send them back, letting other Endpoints subscribe to our\u00a0work.</p>\n<p>You can just imagine scenarios that might find that useful: wanna add a watermark or overlay on each peer video? Sure. Dump it to file before that watermark is added? Done. Mix videos and stream them as one using RTMP protocol? Not easy but doable. Capture an audio track and send it directly to Speech-To-Text. We can do it. Or maybe you need to turn an SFU to MCU architecture? That\u2019s tough but possible. That list is\u00a0endless.</p>\n<p>We created sample Endpoints for HLS output and obviously for WebRTC, but we\u2019ll keep working to provide more plug-and-play Endpoints for some common scenarios. Everything else it\u2019s up to you\u200a\u2014\u200awhat bricks you\u2019re going to use to build the app you\u00a0need?</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cfde806c5beb\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/modular-rtc-engine-is-our-little-big-revolution-in-video-conferencing-cfde806c5beb\">Modular RTC Engine is our little-big revolution in video conferencing</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2Dp2V9J8Ro-6VGXgAZo9eQ.png\"></figure><p>There are already quite a few WebRTC SFU implementations in different programming languages. They\u2019ve got their pros and cons, but the biggest problem about them is that you need to take them as they are. If you need to do something extraordinary, like creating a custom logic, there is a lot of work you need to do. Probably you need to rewrite almost everything from the original library to finally get something that matches your requirement. But the result could still be hardly reusable.</p>\n<p>We\u2019ve made Membrane as a solution for that kind of trouble. That\u2019s why we decided on the pipeline to be the core concept of the framework. And that\u2019s why we have made it easy to create your own element for the pipeline besides the ones we provided. That modularity is the main advantage of Membrane\u2019s approach.</p>\n<p>Later when we started working on our WebRTC implementation we concentrated on implementing the SFU architecture and making things work. We encapsulated the pipeline inside RTC Engine, and we made it do nothing more, but to receive a stream from each peer and to transfer it to other peers (OK, many other things happen there, but they\u2019re less directly related to media transferring).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/631/0*3bgiXj8_DXh697lK\"></figure><p>Technically, the RTC Engine is still a pipeline, so now we decided to rebuild it and make it available to add new functionalities. What kind? You can decide for yourself. With the new architecture of the Membrane RTC Engine, we give you the possibility to arrange your SFU server however you\u00a0need.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/631/0*DHT51fKr5Clu35W5\"></figure><p>But let\u2019s talk about the basic configuration. We\u2019ve got an RTC Engine running on some machine with a basic configuration for WebRTC connections. After you establish a connection with the server it will send info to the RTC Engine about a new peer connected. RTC Engine will create a process called Endpoint (based on the specification we provide) for each connected peer. An Endpoint is a new abstraction that allows us to connect different types of I/O within the RTC Engine. In our case, it will be a WebRTC type Endpoint. Next, our Endpoint will receive from the RTC Engine the list of tracks broadcasted by other Endpoints and can subscribe to each of those.. (Or not. You may write some custom logic for that if you need it). After subscription, your Endpoint will start receiving data from the broadcaster and pass it to your\u00a0browser.</p>\n<p>Accordingly, if you start sending data, your Endpoint will send a message to the RTC Engine that it\u2019s starting broadcasting. RTC Engine will pass this message to other Endpoints, and they\u2019ll subscribe (or not) to your broadcast.</p>\n<p>So, what is so revolutionary here? Let\u2019s Imagine that you have an existing application like that\u200a\u2014\u200aa simple video conference application, and you want to record each peer video to a file. Now you can do this without changing the whole SFU application. All you need is to create a new Endpoint that will subscribe to each peer broadcast, and write it down into a file. It won\u2019t require much work, because that Endpoint is a regular Membrane Bin. One new thing is, to receive data from the other endpoints, it needs to register into the RTC Engine, and after receiving a message about currently available tracks, it needs to answer with proper subscription info. That\u2019s all. The rest is just a simple pipeline\u00a0linking:</p>\n<p>link_bin_input() |&gt; to(:encoder) |&gt; to(:file_sink)</p>\n<p>We can also create a filter Endpoint. Like in the previous example, we can subscribe to some tracks, process them and then send them back, letting other Endpoints subscribe to our\u00a0work.</p>\n<p>You can just imagine scenarios that might find that useful: wanna add a watermark or overlay on each peer video? Sure. Dump it to file before that watermark is added? Done. Mix videos and stream them as one using RTMP protocol? Not easy but doable. Capture an audio track and send it directly to Speech-To-Text. We can do it. Or maybe you need to turn an SFU to MCU architecture? That\u2019s tough but possible. That list is\u00a0endless.</p>\n<p>We created sample Endpoints for HLS output and obviously for WebRTC, but we\u2019ll keep working to provide more plug-and-play Endpoints for some common scenarios. Everything else it\u2019s up to you\u200a\u2014\u200awhat bricks you\u2019re going to use to build the app you\u00a0need?</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=cfde806c5beb\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/modular-rtc-engine-is-our-little-big-revolution-in-video-conferencing-cfde806c5beb\">Modular RTC Engine is our little-big revolution in video conferencing</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "multimedia",
                "streaming",
                "membrane",
                "elixir",
                "webrtc"
            ]
        },
        {
            "title": "Introduction to manual gestures and touch events",
            "pubDate": "2021-12-22 14:40:21",
            "link": "https://blog.swmansion.com/introduction-to-manual-gestures-and-touch-events-a1dde7c98612?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/a1dde7c98612",
            "author": "Jakub Piasecki",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*pYtRxar0CJsdUzCDAe53Nw.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pYtRxar0CJsdUzCDAe53Nw.png\"></figure><p>One of the most requested features of Gesture Handler has been the ability to directly manipulate the state of gestures. With the newly released Gesture Handler 2.0, we introduced the new \u201cmanual gesture\u201d API which fills that demand (read <a href=\"https://blog.swmansion.com/introducing-gesture-handler-2-0-50515f1c4afc\">the announcement post here</a> to learn about other changes we made in Gesture Handler 2.0), thus opening up a lot of new possibilities for gesture-based interactions. In this article we explore this new feature while building a simple React Native application.</p>\n<h4><strong>How does it\u00a0work?</strong></h4>\n<p>At the core of this functionality are newly introduced touch events. They are sent every time a pointer gets updated while the gesture is active or hasn\u2019t yet recognized nor failed, carrying information about all fingers tracked by the gesture, as well as those that have been changed since the last\u00a0event.</p>\n<p>There are four types of touch\u00a0events:</p>\n<ul>\n<li>TOUCHES_DOWN\u200a\u2014\u200asent every time a finger is placed on the screen and is picked up by the\u00a0gesture</li>\n<li>TOUCHES_UP\u200a\u2014\u200asent every time a finger tracked by the gesture has been lifted from the\u00a0screen</li>\n<li>TOUCHES_MOVE\u200a\u2014\u200asent every time a finger tracked by the gesture is\u00a0moved</li>\n<li>TOUCHES_CANCELLED\u200a\u2014\u200asend when some (usually all) pointers tracked by the gesture have been cancelled, for example when the gesture\u00a0fails.</li>\n</ul>\n<p>These events can be handled in the same way as other events, each one of them has associated callback that gets called upon receiving the\u00a0event.</p>\n<h4><strong>Let\u2019s see it in\u00a0action</strong></h4>\n<p>To demonstrate this new feature we will build an app that displays a full-screen pane with a number of discs. Each disc can be panned and pinched in order to change its position and size. As gesture-handler works best with react-native-reanimated, we will use that library to power gesture-based interactions. Here is how this app would\u00a0look.</p>\n<a href=\"https://medium.com/media/77909e585ae3a5e5eb11b2abd6a65979/href\">https://medium.com/media/77909e585ae3a5e5eb11b2abd6a65979/href</a><p>Making gestures work properly in such an app may be quite tricky\u200a\u2014\u200aif we attach gesture recognizers to each individual disc, small discs can be really difficult to hit (to make it larger you\u2019ll need to fit two fingers within the disc area). We can\u2019t really just make the hit area larger for each disc, as it would obstruct the hit area of other nearby discs. It turns out that this can\u2019t really be solved using the set of declarative gesture properties from the old version of gesture handler, but the new manual gesture feature from Gesture Handler 2.0 makes such a scenario relatively straightforward to implement. One way this can be solved is by making each disc hit area to be the full screen, and allow for certain gestures to activate based on proximity, e.g., pan would only recognize when we are within the disc bounds, and pinch would activate if the central point between the fingers is within the disc\u00a0bounds.</p>\n<p>We can begin by creating a Disc component that will render a ball with specified size and color, and its children wrapped within a view filling the entire screen. This will allow us to capture every touch, even ones that occur outside the disc. We use reanimated\u2019s shared values to make disc offset (translation) and scale animatable.</p>\n<a href=\"https://medium.com/media/e869775dd5d69e025399e799d2578068/href\">https://medium.com/media/e869775dd5d69e025399e799d2578068/href</a><p>Below, we show the component responsible for rendering discs with different sizes. Discs need to be nested to allow for events to be delivered to all of them instead of just the top-most\u00a0one.</p>\n<a href=\"https://medium.com/media/5563b1bf1dda9322d5efad9c98d7e27c/href\">https://medium.com/media/5563b1bf1dda9322d5efad9c98d7e27c/href</a><p>In order to add interaction to the discs we need to add shared values to store state of the transformations:</p>\n<a href=\"https://medium.com/media/59faf8e772df78d9ad5b8aeea0904a44/href\">https://medium.com/media/59faf8e772df78d9ad5b8aeea0904a44/href</a><p>Now we can create gesture configurations for the disc. We want to be able to move and scale it, so we need to create Pan and Pinch gesture objects. In both cases we want to use and update the relevant saved value to avoid the disc jumping back to its original position or\u00a0size.</p>\n<a href=\"https://medium.com/media/5b38ba2675c3705ca18aca4c63263557/href\">https://medium.com/media/5b38ba2675c3705ca18aca4c63263557/href</a><p>We also have to wrap rendered views with GestureDetector and pass gesture configs to it. In this case we will use Simultaneous to compose them because we want to allow both of them to be activated at the same\u00a0time.</p>\n<a href=\"https://medium.com/media/e65b77666e458110a4fe0132df81600a/href\">https://medium.com/media/e65b77666e458110a4fe0132df81600a/href</a><p>If we try it now we will see that only the smallest disc is responding to the touches and it doesn\u2019t matter where we touch the screen. That\u2019s because the view containing it is filling the entire screen and the pan gesture doesn\u2019t have any activation constraints, so it activates every time you move a finger cancelling other gestures (the same goes for pinch). We would like the pinch to be able to activate only when its focal point is inside the disc, and pan only when the finger is placed inside the disc or the central point is inside the disc. That\u2019s where touch events come into play as they allow us to check that easily. First we will make a helper function checking if a point is inside a\u00a0view:</p>\n<a href=\"https://medium.com/media/cf4bba7425c902ce664545a8219c1cf0/href\">https://medium.com/media/cf4bba7425c902ce664545a8219c1cf0/href</a><p>Next, we can add touch event callbacks. In the case of a pinch, we want it to activate when the central point is inside the disc and fail otherwise.</p>\n<a href=\"https://medium.com/media/3e2b02ea5cf98fb647234f4516e5c503/href\">https://medium.com/media/3e2b02ea5cf98fb647234f4516e5c503/href</a><p>For this example we want the discs to be able to be moved and scaled at the same time, because of that we need to handle situations where fingers are placed outside the disc\u200a\u2014\u200ait should be possible to move it when just the central point is inside of it. The simplest way to accomplish this is to use the new manualActivation feature that will prevent the pan gesture from activating by itself. This way we can utilize onTouchesMove to check whether the middle point between the fingers (in case of one finger that would be its position) is inside the disc and activate the pan if it\u00a0is.</p>\n<a href=\"https://medium.com/media/508d162f9e4b34d104cff4ad30848ed5/href\">https://medium.com/media/508d162f9e4b34d104cff4ad30848ed5/href</a><p>That\u2019s it! Gesture interactions work as expected, although it lacks some sort of visual feedback. Adding it is very straightforward though, so we won\u2019t describe it here but it\u2019s included in the complete code of the example <a href=\"https://gist.github.com/j-piasecki/c820b5728951ceaa29f35fb68518e0b2\">here</a> if you want to check it\u00a0out.</p>\n<p>In this article we used touch events to manually control the state of Pan and Pinch gesture handlers. You can do the same with all built-in handlers from gesture-handler library, but they also allow you to go beyond what the library provides and build a completely custom handler using touch events in conjunction with the newly introduced Manual gesture (check out <a href=\"https://docs.swmansion.com/react-native-gesture-handler/docs/api/gestures/manual-gesture\">Manual gesture documentation website</a> for more information).</p>\n<p><em>The work on Gesture Handler 2 and the new manual gesture feature has been sponsored by </em><a href=\"https://shopify.engineering/\"><em>Shopify</em></a><em>\u00a0\ud83d\ude4c.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a1dde7c98612\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/introduction-to-manual-gestures-and-touch-events-a1dde7c98612\">Introduction to manual gestures and touch events</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*pYtRxar0CJsdUzCDAe53Nw.png\"></figure><p>One of the most requested features of Gesture Handler has been the ability to directly manipulate the state of gestures. With the newly released Gesture Handler 2.0, we introduced the new \u201cmanual gesture\u201d API which fills that demand (read <a href=\"https://blog.swmansion.com/introducing-gesture-handler-2-0-50515f1c4afc\">the announcement post here</a> to learn about other changes we made in Gesture Handler 2.0), thus opening up a lot of new possibilities for gesture-based interactions. In this article we explore this new feature while building a simple React Native application.</p>\n<h4><strong>How does it\u00a0work?</strong></h4>\n<p>At the core of this functionality are newly introduced touch events. They are sent every time a pointer gets updated while the gesture is active or hasn\u2019t yet recognized nor failed, carrying information about all fingers tracked by the gesture, as well as those that have been changed since the last\u00a0event.</p>\n<p>There are four types of touch\u00a0events:</p>\n<ul>\n<li>TOUCHES_DOWN\u200a\u2014\u200asent every time a finger is placed on the screen and is picked up by the\u00a0gesture</li>\n<li>TOUCHES_UP\u200a\u2014\u200asent every time a finger tracked by the gesture has been lifted from the\u00a0screen</li>\n<li>TOUCHES_MOVE\u200a\u2014\u200asent every time a finger tracked by the gesture is\u00a0moved</li>\n<li>TOUCHES_CANCELLED\u200a\u2014\u200asend when some (usually all) pointers tracked by the gesture have been cancelled, for example when the gesture\u00a0fails.</li>\n</ul>\n<p>These events can be handled in the same way as other events, each one of them has associated callback that gets called upon receiving the\u00a0event.</p>\n<h4><strong>Let\u2019s see it in\u00a0action</strong></h4>\n<p>To demonstrate this new feature we will build an app that displays a full-screen pane with a number of discs. Each disc can be panned and pinched in order to change its position and size. As gesture-handler works best with react-native-reanimated, we will use that library to power gesture-based interactions. Here is how this app would\u00a0look.</p>\n<a href=\"https://medium.com/media/77909e585ae3a5e5eb11b2abd6a65979/href\">https://medium.com/media/77909e585ae3a5e5eb11b2abd6a65979/href</a><p>Making gestures work properly in such an app may be quite tricky\u200a\u2014\u200aif we attach gesture recognizers to each individual disc, small discs can be really difficult to hit (to make it larger you\u2019ll need to fit two fingers within the disc area). We can\u2019t really just make the hit area larger for each disc, as it would obstruct the hit area of other nearby discs. It turns out that this can\u2019t really be solved using the set of declarative gesture properties from the old version of gesture handler, but the new manual gesture feature from Gesture Handler 2.0 makes such a scenario relatively straightforward to implement. One way this can be solved is by making each disc hit area to be the full screen, and allow for certain gestures to activate based on proximity, e.g., pan would only recognize when we are within the disc bounds, and pinch would activate if the central point between the fingers is within the disc\u00a0bounds.</p>\n<p>We can begin by creating a Disc component that will render a ball with specified size and color, and its children wrapped within a view filling the entire screen. This will allow us to capture every touch, even ones that occur outside the disc. We use reanimated\u2019s shared values to make disc offset (translation) and scale animatable.</p>\n<a href=\"https://medium.com/media/e869775dd5d69e025399e799d2578068/href\">https://medium.com/media/e869775dd5d69e025399e799d2578068/href</a><p>Below, we show the component responsible for rendering discs with different sizes. Discs need to be nested to allow for events to be delivered to all of them instead of just the top-most\u00a0one.</p>\n<a href=\"https://medium.com/media/5563b1bf1dda9322d5efad9c98d7e27c/href\">https://medium.com/media/5563b1bf1dda9322d5efad9c98d7e27c/href</a><p>In order to add interaction to the discs we need to add shared values to store state of the transformations:</p>\n<a href=\"https://medium.com/media/59faf8e772df78d9ad5b8aeea0904a44/href\">https://medium.com/media/59faf8e772df78d9ad5b8aeea0904a44/href</a><p>Now we can create gesture configurations for the disc. We want to be able to move and scale it, so we need to create Pan and Pinch gesture objects. In both cases we want to use and update the relevant saved value to avoid the disc jumping back to its original position or\u00a0size.</p>\n<a href=\"https://medium.com/media/5b38ba2675c3705ca18aca4c63263557/href\">https://medium.com/media/5b38ba2675c3705ca18aca4c63263557/href</a><p>We also have to wrap rendered views with GestureDetector and pass gesture configs to it. In this case we will use Simultaneous to compose them because we want to allow both of them to be activated at the same\u00a0time.</p>\n<a href=\"https://medium.com/media/e65b77666e458110a4fe0132df81600a/href\">https://medium.com/media/e65b77666e458110a4fe0132df81600a/href</a><p>If we try it now we will see that only the smallest disc is responding to the touches and it doesn\u2019t matter where we touch the screen. That\u2019s because the view containing it is filling the entire screen and the pan gesture doesn\u2019t have any activation constraints, so it activates every time you move a finger cancelling other gestures (the same goes for pinch). We would like the pinch to be able to activate only when its focal point is inside the disc, and pan only when the finger is placed inside the disc or the central point is inside the disc. That\u2019s where touch events come into play as they allow us to check that easily. First we will make a helper function checking if a point is inside a\u00a0view:</p>\n<a href=\"https://medium.com/media/cf4bba7425c902ce664545a8219c1cf0/href\">https://medium.com/media/cf4bba7425c902ce664545a8219c1cf0/href</a><p>Next, we can add touch event callbacks. In the case of a pinch, we want it to activate when the central point is inside the disc and fail otherwise.</p>\n<a href=\"https://medium.com/media/3e2b02ea5cf98fb647234f4516e5c503/href\">https://medium.com/media/3e2b02ea5cf98fb647234f4516e5c503/href</a><p>For this example we want the discs to be able to be moved and scaled at the same time, because of that we need to handle situations where fingers are placed outside the disc\u200a\u2014\u200ait should be possible to move it when just the central point is inside of it. The simplest way to accomplish this is to use the new manualActivation feature that will prevent the pan gesture from activating by itself. This way we can utilize onTouchesMove to check whether the middle point between the fingers (in case of one finger that would be its position) is inside the disc and activate the pan if it\u00a0is.</p>\n<a href=\"https://medium.com/media/508d162f9e4b34d104cff4ad30848ed5/href\">https://medium.com/media/508d162f9e4b34d104cff4ad30848ed5/href</a><p>That\u2019s it! Gesture interactions work as expected, although it lacks some sort of visual feedback. Adding it is very straightforward though, so we won\u2019t describe it here but it\u2019s included in the complete code of the example <a href=\"https://gist.github.com/j-piasecki/c820b5728951ceaa29f35fb68518e0b2\">here</a> if you want to check it\u00a0out.</p>\n<p>In this article we used touch events to manually control the state of Pan and Pinch gesture handlers. You can do the same with all built-in handlers from gesture-handler library, but they also allow you to go beyond what the library provides and build a completely custom handler using touch events in conjunction with the newly introduced Manual gesture (check out <a href=\"https://docs.swmansion.com/react-native-gesture-handler/docs/api/gestures/manual-gesture\">Manual gesture documentation website</a> for more information).</p>\n<p><em>The work on Gesture Handler 2 and the new manual gesture feature has been sponsored by </em><a href=\"https://shopify.engineering/\"><em>Shopify</em></a><em>\u00a0\ud83d\ude4c.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a1dde7c98612\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/introduction-to-manual-gestures-and-touch-events-a1dde7c98612\">Introduction to manual gestures and touch events</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "reanimated",
                "react",
                "gesture-handler",
                "react-native"
            ]
        },
        {
            "title": "How to Build and Distribute Any React Native App With New Expo Services",
            "pubDate": "2021-12-13 11:27:36",
            "link": "https://blog.swmansion.com/how-to-build-and-distribute-any-react-native-app-with-new-expo-services-529a56cec852?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/529a56cec852",
            "author": "Dominik Sokal",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*zyJtq8RHFZzYVBNXVzS2yA.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zyJtq8RHFZzYVBNXVzS2yA.png\"></figure><p>Software Mansion has been actively contributing to Expo since 2017. In addition to working on open-source parts of Expo, like Expo modules and Expo CLI, we help build and maintain the Expo infrastructure. One of the efforts that we are proud of is our work on Expo\u2019s build\u00a0service.</p>\n<p><a href=\"https://blog.expo.dev/expo-application-services-eas-build-and-submit-fc1d1476aa2e\">Expo announced EAS Build last year</a>. The service lets you build and sign any React Native project for both Android and iOS platforms, from any operating system (even from Windows!). Since the initial release, the service has gone a long way to <a href=\"https://blog.expo.dev/introducing-eas-395d4809cc6f\">reach General Availability in November 2021</a>. EAS Build comes with the complimentary service - EAS Submit - that does the heavy lifting when you decide to share your application with the general audience or just submit another build to the store. The new tooling - EAS CLI - integrates seamlessly with your Expo project. You\u2019ll quickly consider it to be another \u201cfast-forward button\u201d from the Expo\u00a0team.</p>\n<p>In this blog post, I\u2019d like to show how to use all the new features that EAS Build and EAS Submit bring to the Expo ecosystem. After a few-minute read, you\u2019ll be able to build and distribute any React Native project using only a few simple commands.</p>\n<h4>Creating a New\u00a0Project</h4>\n<p>Let\u2019s build a project that uses Bluetooth to scan for nearby devices. <a href=\"https://expo.canny.io/feature-requests/p/bluetooth-1\">Adding Bluetooth support</a> was one of the top requested features by mobile developers using Expo. Expo still doesn\u2019t provide its own Bluetooth module, but you can integrate any third-party npm package, like <a href=\"https://github.com/dotintent/react-native-ble-plx\">react-native-ble-plx</a>, with your Expo-powered app with minimal\u00a0effort.</p>\n<p>Unlike the classic Expo build service (expo build:[android|ios]), EAS Build supports building React Native projects with custom native code. <em>You can even build an Android or iOS project that does not use React Native at all, but this is an unadvertised feature and requires a bit of\u00a0hacking.</em></p>\n<p>I initialized my project with expo init and chose the bare template. The bare template includes the native Android and iOS projects. This let me install and configure the react-native-ble-plx package which is one of the most popular options for Bluetooth in React\u00a0Native.</p>\n<p>After adding a button to start/stop scanning nearby devices, integrating with Bluetooth, and displaying the device list, the app is ready for distribution.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/510/1*bHQgGQ_ddDd_jC7j-S3HyQ.png\"><figcaption>Simple Bluetooth Scanner</figcaption></figure><p>You can find the app\u2019s source code at <a href=\"https://github.com/dsokal/bluetooth-scanner\">https://github.com/dsokal/bluetooth-scanner</a>.</p>\n<h4>Start Using\u00a0EAS</h4>\n<p>Using EAS Build &amp; Submit does not require too much configuration. All you need is the new CLI called EAS CLI. You can install it like any other npm package - npm install -g\u00a0eas-cli.</p>\n<p>Installing the CLI is the first step. The second and last step is configuring the project to be built with EAS Build. Run eas build:configure and choose which platforms you want to configure. <em>Tip: alternatively, you can just run </em><em>eas build to both configure your project and start a\u00a0build.</em></p>\n<p>EAS Build &amp; Submit are configured with the eas.json file. EAS CLI uses the concept of build/submit profiles so that you can define your development and production workflows once and then switch between them with the --profile PROFILE_NAME option. The default eas.json looks something like\u00a0this:</p>\n<a href=\"https://medium.com/media/1579b9d137d53d89f5de74714d13bda7/href\">https://medium.com/media/1579b9d137d53d89f5de74714d13bda7/href</a><p>It comes with predefined build profiles that allow you to take advantage of the most powerful Expo/EAS features: <a href=\"https://docs.expo.dev/development/introduction/\">Development Builds</a>, <a href=\"https://docs.expo.dev/build/internal-distribution/\">Internal Distribution</a>, and credentials management.</p>\n<h4>Development Builds</h4>\n<p>Mobile app development can be frustrating. An Android or iOS build of your app can take a few minutes and when you first start building your app, you\u2019ll have to rebuild the project quite often. React Native itself can be an answer to this problem. You usually don\u2019t need to touch the native code, and instead, you\u2019ll change the JavaScript code. Because of that, native project (re)builds don\u2019t take\u00a0long.</p>\n<p>When starting your mobile app project in Expo, you\u2019re equipped with a great tool called <a href=\"https://expo.dev/client\">Expo Go</a>. It lets you develop your app without the need to build native projects. Install the app onto your phone, run expo start in the project directory, scan the QR code, and start developing. Every time you change the code, the app refreshes in the blink of an\u00a0eye.</p>\n<p>The problem with Expo Go is that it comes with a preset collection of native modules. This is fine for many mobile app use-cases but can be limiting. If you want to use a custom module (e.g. react-native-ble-plx) you won\u2019t be able to properly test your app with Expo Go. Development Builds are the answer to the problem. You can build your custom Expo Go-like client app that will contain all the native modules your app needs. Also, unlike the Expo Go app, the development build won\u2019t include all Expo modules that you don\u2019t use. This makes your custom client app lightweight and closer to your production environment.</p>\n<p>To use Development Builds, install theexpo-dev-client package in your project, follow <a href=\"https://docs.expo.dev/development/installation/\">the instructions on the page</a> (only if using bare workflow), and then run eas build --profile development. When building for iOS, you will need to register a device with EAS before it can run your app through Internal Distribution. This step is covered in the next paragraph. <em>Keep in mind that Development Builds are still in\u00a0preview!</em></p>\n<h4>Internal Distribution</h4>\n<p>Whenever you\u2019re working on a new feature for your app, you want to make sure it works the way it was designed. This usually involves building your app and sharing it with a QA team. Even though the task is fairly simple on Android (you just need to build an APK instead of AAB), there are a few problems on iOS when using TestFlight:</p>\n<ul>\n<li>The processing time of your new build can take even as long as 30\u00a0minutes.</li>\n<li>TestFlight can only have one active build at a\u00a0time.</li>\n<li>TestFlight app needs to be installed on the iPhone/iPad.</li>\n</ul>\n<p>EAS Build streamlines the process of building apps for internal usage with Internal Distribution. Just set \"distribution\": \"internal\" in the build profile (or use the predefined build profile - preview) and you can share your build with anyone within a few\u00a0minutes.</p>\n<p>On iOS, you\u2019ll also need to register all devices (iPhones and iPads) with eas device:create but it\u2019s as simple as scanning a QR code and following instructions displayed on the\u00a0screen.</p>\n<p>When you have registered all your devices, run eas build --profile preview and you\u2019ll get a sharable URL for your build (and a QR code). Open it on any of the registered devices and start testing the app with a single click of the installation button.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*17Te9tbAIwj9w89xpqjOsQ.png\"><figcaption>Scan the QR code to install the\u00a0app</figcaption></figure><h4>Building App for Public Distribution</h4>\n<p>When the time comes (and the QA team approves the latest build) you will want to distribute the app on the Google Play Store and Apple App Store. EAS Build comes in handy not only for you but for your whole team. You configure the project once and the whole team can benefit from that. Everyone added to the Expo organization can run builds the same way as the person who configured the project. Similarly, using the same exact command, you can run a build from CI. On top of that, when building a mobile app, you sometimes need to be an expert on the credentials needed to sign your app (you need to know what\u2019s Distribution Certificate, Provisioning Profile, Push Notifications Key, Keystore, and so\u00a0on).</p>\n<p>EAS Build allows you to build your native project in the cloud, in the already pre-configured environment, and also takes care of credentials management. This means you don\u2019t need to have Android Studio and Xcode installed on your computer. You don\u2019t even need to have a Mac to build an iOS app. Lastly, you don\u2019t need to know what\u2019s a Keystore and even how to generate\u00a0one.</p>\n<p>Building a React Native project for store distribution is just a matter of running eas build in the project directory. EAS CLI walks you through the entire credentials management process and prints the URL to the build details page where you can track the build\u2019s progress and view build logs. When the build completes you\u2019ll get a URL to the build artifact.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*d5icuQDBP3EpZ-a54NWZiA.png\"><figcaption>Run <strong>eas build</strong> to build your project on EAS\u00a0servers</figcaption></figure><h4>Submitting App to App\u00a0Store</h4>\n<p>You have your app archive ready to submit to the app store. EAS Submit can help you out with the task. If you\u2019ve used EAS Build to build the project, you\u2019ll be astonished at how easy it is to submit your latest build to the app store. At the same time, EAS Submit also supports uploading apps that were built elsewhere.</p>\n<p>The only limitation of the app submission process is that you\u2019ll have to <a href=\"https://github.com/expo/fyi/blob/main/first-android-submission.md\">upload your first Android build to the Google Play Store manually</a>. This is the limitation of the Google Play Store that will hopefully be overcome in the future. iOS part of the task is more straightforward - you can upload your first build to the Apple App Store without manual intervention.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9UcnJVHH76rZmLaJcUmbNQ.png\"><figcaption>Uploading the latest iOS build to the Apple App\u00a0Store</figcaption></figure><p>Run eas submit -p PLATFORM --latest to submit the latest build to the app store. If you haven\u2019t used EAS Submit before, EAS CLI is going to ask you for your Apple ID credentials (to generate an API Key) or <a href=\"https://github.com/expo/fyi/blob/main/creating-google-service-account.md\">Google Service Account Key</a>. If you choose to store the API keys on EAS servers, all subsequent submissions are going to be already pre-configured.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rqR45MZIrfV4pmspw_7S0w.png\"><figcaption>The iOS submission can be later reviewed in the App Store\u00a0Connect</figcaption></figure><h4>Automating Build &amp; Submit\u00a0Process</h4>\n<p>As you\u2019ve already seen, EAS Build &amp; Submit can make your app development workflows easier for you and your team. However, this is not yet everything that EAS has to offer. You can further automate your workflows with automatic build submissions. That is, you can tell EAS to submit your app to the appropriate app store on a successful project build. To do so, run the build the same way as previously but add the --auto-submit flag. If you want to build your project for both Android and iOS, and upload the builds to the app stores afterward run eas build -p all --auto-submit and enjoy your cup of coffee - EAS is going to take care of the\u00a0rest.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g4J7iis5i189kiipAbDzZQ.png\"><figcaption>Automating App Store submissions feels like\u00a0magic</figcaption></figure><p>If the EAS-provided automatic submissions are not flexible enough for you, you can always take advantage of build/submit <a href=\"https://docs.expo.dev/eas/webhooks/\">webhooks</a>. You can build an HTTP server, expose the API to the Internet, and register it with eas webhook:create. Your API endpoint will be called with all relevant metadata on every successful or failed build/submit. You can, for instance, implement your own logic that\u2019s going to upload your Android build to alternative stores that are not yet supported by\u00a0EAS.</p>\n<h4>Focus On Important Things</h4>\n<p>Building and submitting Expo/React Native projects has never been easier than now. There has always been a not-well-answered question in the community\u200a\u2014\u200a\u201cShould I use Expo or React Native?\u201d. The answer seems obvious now\u200a\u2014\u200a\u201cIt doesn\u2019t matter, but Expo is the right choice if you want to save time.\u201d. With EAS Build &amp; Submit you can focus on what\u2019s the most important for the success of your mobile app\u200a\u2014\u200athe app\u00a0itself.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=529a56cec852\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/how-to-build-and-distribute-any-react-native-app-with-new-expo-services-529a56cec852\">How to Build and Distribute Any React Native App With New Expo Services</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zyJtq8RHFZzYVBNXVzS2yA.png\"></figure><p>Software Mansion has been actively contributing to Expo since 2017. In addition to working on open-source parts of Expo, like Expo modules and Expo CLI, we help build and maintain the Expo infrastructure. One of the efforts that we are proud of is our work on Expo\u2019s build\u00a0service.</p>\n<p><a href=\"https://blog.expo.dev/expo-application-services-eas-build-and-submit-fc1d1476aa2e\">Expo announced EAS Build last year</a>. The service lets you build and sign any React Native project for both Android and iOS platforms, from any operating system (even from Windows!). Since the initial release, the service has gone a long way to <a href=\"https://blog.expo.dev/introducing-eas-395d4809cc6f\">reach General Availability in November 2021</a>. EAS Build comes with the complimentary service - EAS Submit - that does the heavy lifting when you decide to share your application with the general audience or just submit another build to the store. The new tooling - EAS CLI - integrates seamlessly with your Expo project. You\u2019ll quickly consider it to be another \u201cfast-forward button\u201d from the Expo\u00a0team.</p>\n<p>In this blog post, I\u2019d like to show how to use all the new features that EAS Build and EAS Submit bring to the Expo ecosystem. After a few-minute read, you\u2019ll be able to build and distribute any React Native project using only a few simple commands.</p>\n<h4>Creating a New\u00a0Project</h4>\n<p>Let\u2019s build a project that uses Bluetooth to scan for nearby devices. <a href=\"https://expo.canny.io/feature-requests/p/bluetooth-1\">Adding Bluetooth support</a> was one of the top requested features by mobile developers using Expo. Expo still doesn\u2019t provide its own Bluetooth module, but you can integrate any third-party npm package, like <a href=\"https://github.com/dotintent/react-native-ble-plx\">react-native-ble-plx</a>, with your Expo-powered app with minimal\u00a0effort.</p>\n<p>Unlike the classic Expo build service (expo build:[android|ios]), EAS Build supports building React Native projects with custom native code. <em>You can even build an Android or iOS project that does not use React Native at all, but this is an unadvertised feature and requires a bit of\u00a0hacking.</em></p>\n<p>I initialized my project with expo init and chose the bare template. The bare template includes the native Android and iOS projects. This let me install and configure the react-native-ble-plx package which is one of the most popular options for Bluetooth in React\u00a0Native.</p>\n<p>After adding a button to start/stop scanning nearby devices, integrating with Bluetooth, and displaying the device list, the app is ready for distribution.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/510/1*bHQgGQ_ddDd_jC7j-S3HyQ.png\"><figcaption>Simple Bluetooth Scanner</figcaption></figure><p>You can find the app\u2019s source code at <a href=\"https://github.com/dsokal/bluetooth-scanner\">https://github.com/dsokal/bluetooth-scanner</a>.</p>\n<h4>Start Using\u00a0EAS</h4>\n<p>Using EAS Build &amp; Submit does not require too much configuration. All you need is the new CLI called EAS CLI. You can install it like any other npm package - npm install -g\u00a0eas-cli.</p>\n<p>Installing the CLI is the first step. The second and last step is configuring the project to be built with EAS Build. Run eas build:configure and choose which platforms you want to configure. <em>Tip: alternatively, you can just run </em><em>eas build to both configure your project and start a\u00a0build.</em></p>\n<p>EAS Build &amp; Submit are configured with the eas.json file. EAS CLI uses the concept of build/submit profiles so that you can define your development and production workflows once and then switch between them with the --profile PROFILE_NAME option. The default eas.json looks something like\u00a0this:</p>\n<a href=\"https://medium.com/media/1579b9d137d53d89f5de74714d13bda7/href\">https://medium.com/media/1579b9d137d53d89f5de74714d13bda7/href</a><p>It comes with predefined build profiles that allow you to take advantage of the most powerful Expo/EAS features: <a href=\"https://docs.expo.dev/development/introduction/\">Development Builds</a>, <a href=\"https://docs.expo.dev/build/internal-distribution/\">Internal Distribution</a>, and credentials management.</p>\n<h4>Development Builds</h4>\n<p>Mobile app development can be frustrating. An Android or iOS build of your app can take a few minutes and when you first start building your app, you\u2019ll have to rebuild the project quite often. React Native itself can be an answer to this problem. You usually don\u2019t need to touch the native code, and instead, you\u2019ll change the JavaScript code. Because of that, native project (re)builds don\u2019t take\u00a0long.</p>\n<p>When starting your mobile app project in Expo, you\u2019re equipped with a great tool called <a href=\"https://expo.dev/client\">Expo Go</a>. It lets you develop your app without the need to build native projects. Install the app onto your phone, run expo start in the project directory, scan the QR code, and start developing. Every time you change the code, the app refreshes in the blink of an\u00a0eye.</p>\n<p>The problem with Expo Go is that it comes with a preset collection of native modules. This is fine for many mobile app use-cases but can be limiting. If you want to use a custom module (e.g. react-native-ble-plx) you won\u2019t be able to properly test your app with Expo Go. Development Builds are the answer to the problem. You can build your custom Expo Go-like client app that will contain all the native modules your app needs. Also, unlike the Expo Go app, the development build won\u2019t include all Expo modules that you don\u2019t use. This makes your custom client app lightweight and closer to your production environment.</p>\n<p>To use Development Builds, install theexpo-dev-client package in your project, follow <a href=\"https://docs.expo.dev/development/installation/\">the instructions on the page</a> (only if using bare workflow), and then run eas build --profile development. When building for iOS, you will need to register a device with EAS before it can run your app through Internal Distribution. This step is covered in the next paragraph. <em>Keep in mind that Development Builds are still in\u00a0preview!</em></p>\n<h4>Internal Distribution</h4>\n<p>Whenever you\u2019re working on a new feature for your app, you want to make sure it works the way it was designed. This usually involves building your app and sharing it with a QA team. Even though the task is fairly simple on Android (you just need to build an APK instead of AAB), there are a few problems on iOS when using TestFlight:</p>\n<ul>\n<li>The processing time of your new build can take even as long as 30\u00a0minutes.</li>\n<li>TestFlight can only have one active build at a\u00a0time.</li>\n<li>TestFlight app needs to be installed on the iPhone/iPad.</li>\n</ul>\n<p>EAS Build streamlines the process of building apps for internal usage with Internal Distribution. Just set \"distribution\": \"internal\" in the build profile (or use the predefined build profile - preview) and you can share your build with anyone within a few\u00a0minutes.</p>\n<p>On iOS, you\u2019ll also need to register all devices (iPhones and iPads) with eas device:create but it\u2019s as simple as scanning a QR code and following instructions displayed on the\u00a0screen.</p>\n<p>When you have registered all your devices, run eas build --profile preview and you\u2019ll get a sharable URL for your build (and a QR code). Open it on any of the registered devices and start testing the app with a single click of the installation button.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*17Te9tbAIwj9w89xpqjOsQ.png\"><figcaption>Scan the QR code to install the\u00a0app</figcaption></figure><h4>Building App for Public Distribution</h4>\n<p>When the time comes (and the QA team approves the latest build) you will want to distribute the app on the Google Play Store and Apple App Store. EAS Build comes in handy not only for you but for your whole team. You configure the project once and the whole team can benefit from that. Everyone added to the Expo organization can run builds the same way as the person who configured the project. Similarly, using the same exact command, you can run a build from CI. On top of that, when building a mobile app, you sometimes need to be an expert on the credentials needed to sign your app (you need to know what\u2019s Distribution Certificate, Provisioning Profile, Push Notifications Key, Keystore, and so\u00a0on).</p>\n<p>EAS Build allows you to build your native project in the cloud, in the already pre-configured environment, and also takes care of credentials management. This means you don\u2019t need to have Android Studio and Xcode installed on your computer. You don\u2019t even need to have a Mac to build an iOS app. Lastly, you don\u2019t need to know what\u2019s a Keystore and even how to generate\u00a0one.</p>\n<p>Building a React Native project for store distribution is just a matter of running eas build in the project directory. EAS CLI walks you through the entire credentials management process and prints the URL to the build details page where you can track the build\u2019s progress and view build logs. When the build completes you\u2019ll get a URL to the build artifact.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*d5icuQDBP3EpZ-a54NWZiA.png\"><figcaption>Run <strong>eas build</strong> to build your project on EAS\u00a0servers</figcaption></figure><h4>Submitting App to App\u00a0Store</h4>\n<p>You have your app archive ready to submit to the app store. EAS Submit can help you out with the task. If you\u2019ve used EAS Build to build the project, you\u2019ll be astonished at how easy it is to submit your latest build to the app store. At the same time, EAS Submit also supports uploading apps that were built elsewhere.</p>\n<p>The only limitation of the app submission process is that you\u2019ll have to <a href=\"https://github.com/expo/fyi/blob/main/first-android-submission.md\">upload your first Android build to the Google Play Store manually</a>. This is the limitation of the Google Play Store that will hopefully be overcome in the future. iOS part of the task is more straightforward - you can upload your first build to the Apple App Store without manual intervention.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*9UcnJVHH76rZmLaJcUmbNQ.png\"><figcaption>Uploading the latest iOS build to the Apple App\u00a0Store</figcaption></figure><p>Run eas submit -p PLATFORM --latest to submit the latest build to the app store. If you haven\u2019t used EAS Submit before, EAS CLI is going to ask you for your Apple ID credentials (to generate an API Key) or <a href=\"https://github.com/expo/fyi/blob/main/creating-google-service-account.md\">Google Service Account Key</a>. If you choose to store the API keys on EAS servers, all subsequent submissions are going to be already pre-configured.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rqR45MZIrfV4pmspw_7S0w.png\"><figcaption>The iOS submission can be later reviewed in the App Store\u00a0Connect</figcaption></figure><h4>Automating Build &amp; Submit\u00a0Process</h4>\n<p>As you\u2019ve already seen, EAS Build &amp; Submit can make your app development workflows easier for you and your team. However, this is not yet everything that EAS has to offer. You can further automate your workflows with automatic build submissions. That is, you can tell EAS to submit your app to the appropriate app store on a successful project build. To do so, run the build the same way as previously but add the --auto-submit flag. If you want to build your project for both Android and iOS, and upload the builds to the app stores afterward run eas build -p all --auto-submit and enjoy your cup of coffee - EAS is going to take care of the\u00a0rest.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*g4J7iis5i189kiipAbDzZQ.png\"><figcaption>Automating App Store submissions feels like\u00a0magic</figcaption></figure><p>If the EAS-provided automatic submissions are not flexible enough for you, you can always take advantage of build/submit <a href=\"https://docs.expo.dev/eas/webhooks/\">webhooks</a>. You can build an HTTP server, expose the API to the Internet, and register it with eas webhook:create. Your API endpoint will be called with all relevant metadata on every successful or failed build/submit. You can, for instance, implement your own logic that\u2019s going to upload your Android build to alternative stores that are not yet supported by\u00a0EAS.</p>\n<h4>Focus On Important Things</h4>\n<p>Building and submitting Expo/React Native projects has never been easier than now. There has always been a not-well-answered question in the community\u200a\u2014\u200a\u201cShould I use Expo or React Native?\u201d. The answer seems obvious now\u200a\u2014\u200a\u201cIt doesn\u2019t matter, but Expo is the right choice if you want to save time.\u201d. With EAS Build &amp; Submit you can focus on what\u2019s the most important for the success of your mobile app\u200a\u2014\u200athe app\u00a0itself.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=529a56cec852\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/how-to-build-and-distribute-any-react-native-app-with-new-expo-services-529a56cec852\">How to Build and Distribute Any React Native App With New Expo Services</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "continuous-integration",
                "continuous-delivery",
                "programming",
                "react-native",
                "expo"
            ]
        },
        {
            "title": "Introducing Gesture Handler 2.0",
            "pubDate": "2021-12-01 14:40:42",
            "link": "https://blog.swmansion.com/introducing-gesture-handler-2-0-50515f1c4afc?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/50515f1c4afc",
            "author": "Jakub Piasecki",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*eM0bbTv3J4kegZJYS1ZpHw.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eM0bbTv3J4kegZJYS1ZpHw.png\"></figure><p>During the last few years Gesture Handler has become one of the core libraries of the React Native ecosystem. It allows for recognizing gestures such as pinch, rotation, or pan, utilizing the native touch system on each platform, and also makes it possible to specify how the gestures should interact with each\u00a0other.</p>\n<p>Today, we are happy to announce the release of Gesture Handler 2.0. It brings an entirely new way of adding gesture-based interactions to your apps and addresses many shortcomings of the previous versions. Gesture Handler 2.0 comes with a new API designed from the ground up. We have spent a lot of time iterating over different concepts of defining gestures and we have settled on one that, in our opinion, makes creating complex gestures much easier. To make the transition to 2.0 more approachable for a huge gesture-handler user base, we are making this new release fully compatible with version 1 (all the APIs from version 1 stay the same). This way, you can upgrade your app even today and decide if and when it makes sense for you to start using the new API. In this post we highlight the key changes in the new API for you to get a sense of how it can help you improve your codebase, and how to take advantage of the new features.</p>\n<h4><strong>One to rule them\u00a0all</strong></h4>\n<p>One of the frequent use cases for our library is to monitor a number of concurrent gestures over a single view (e.g., pan, pinch, rotation of an image). To achieve this with the old API you\u2019d have to nest a number of gesture-specific components often interleaved with react-native\u2019s Views. In Gesture Handler 2 we are taking a different approach with a new GestureDetector component capable of recognizing all types of gestures.</p>\n<p>In the new API, gesture configuration is instantiated using the Gesture object and configured in the builder-like pattern, then passed to the detector component. Let\u2019s look at a simple example of a double\u00a0tap:</p>\n<a href=\"https://medium.com/media/d4f473dc9f7f9fa3920f95f16ed92dc4/href\">https://medium.com/media/d4f473dc9f7f9fa3920f95f16ed92dc4/href</a><p>That may not be very impressive but the improvement can be definitely seen when adding more than one gesture to a component. Instead of creating multiple handlers, and connecting them together using refs, we have introduced a new system of gesture composition.</p>\n<h4><strong>Composing gestures</strong></h4>\n<p>Along all the basic gestures, the Gesture object provides methods for composing gestures:</p>\n<ul>\n<li>Simultaneous\u200a\u2014\u200aall of the gestures can become active at the same\u00a0time.</li>\n<li>Race\u200a\u2014\u200athe first gesture that becomes active cancels other gestures.</li>\n<li>Exclusive\u200a\u2014\u200aassigns priority to the gestures: the first gesture can become active at any time, the second gesture can activate only when the first one fails, third gesture can activate only when the second one fails, and so\u00a0on.</li>\n</ul>\n<p>To demonstrate its capabilities let\u2019s look at a common example: pan, pinch and rotation on a single component.</p>\n<a href=\"https://medium.com/media/2ba5906f3ac385280412e96ca7e29eb2/href\">https://medium.com/media/2ba5906f3ac385280412e96ca7e29eb2/href</a><p>Another important improvement over the 1.0 API is that GestureDetector no longer needs to wrap an actual react-native View component. You can now put any composite component directly under GestureDetector, which helps with extracting gesture-related logic to separate files if that\u2019s the approach you prefer to\u00a0follow.</p>\n<h4><strong>Close integration with Reanimated 2</strong></h4>\n<p>Gesture Handler 2.0 is closely integrated with Reanimated 2. If both libraries are installed, functions set as callbacks to events will be automatically treated as Reanimated\u2019s worklets and GestureDetector will default to utilizing them for synchronous event delivery. Unfortunately, there is one trade off we had to make when designing this new API and it does no longer work with Reanimated 1 and with <a href=\"https://reactnative.dev/docs/animated#event\">React Native\u2019s Animated Events</a> (you could still use that approach via the old Gesture Handler API if you can\u2019t migrate to Reanimated 2 at the moment). One of the main reasons behind this decision is the fact that worklets allow for synchronous communication with the native code which brings us to the most important feature of this\u00a0release.</p>\n<h4><strong>Take full control of your\u00a0gestures</strong></h4>\n<p>We are introducing a new type of events in the Gesture Handler 2.0: touch events. They allow for tracking the position of individual fingers and decide from within the gesture\u2019s callback on when it should activate or fail. When used with the new <a href=\"https://docs.swmansion.com/react-native-gesture-handler/docs/manual-gestures/manual-gestures\">\u201cManual Gesture\u201d</a>, it\u2019s possible to implement almost any gesture recognition logic you may want in your app. This can be used, for example, to recognize users drawing some shapes, or making your pinch gesture only activate when the central point between the fingers is in a certain\u00a0place.</p>\n<p>We are also expanding on this idea and bringing it to the built-in gestures, making it possible to control the activation or failure criteria programmatically from within touch event callbacks as opposed to only having a set of configuration options for each gesture type. In order to use Manual Gesture you\u2019ll need to install Reanimated 2.3 or\u00a0newer.</p>\n<h4><strong>Compatibility with the old\u00a0API</strong></h4>\n<p>While we are going to focus on the new API going forward, the old one is not going away. Moreover, we made sure that it would be cross-compatible with the API introduced in 2.0, that includes specifying interactions between gestures so they can be made to work simultaneously or to wait for others. We are sure you\u2019ll love the new API, but if you don\u2019t want or can\u2019t move to it just yet you still can safely upgrade and take advantage of all the fixes and improvements to Gesture Handler core we are going to be adding to the future 2.x releases.</p>\n<p><em>New Gesture Handler is brought to you by </em><a href=\"https://swmansion.com/\"><em>Software Mansion</em></a><em> and\u00a0</em><a href=\"https://shopify.engineering/\"><em>Shopify</em></a><em>.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50515f1c4afc\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/introducing-gesture-handler-2-0-50515f1c4afc\">Introducing Gesture Handler 2.0</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eM0bbTv3J4kegZJYS1ZpHw.png\"></figure><p>During the last few years Gesture Handler has become one of the core libraries of the React Native ecosystem. It allows for recognizing gestures such as pinch, rotation, or pan, utilizing the native touch system on each platform, and also makes it possible to specify how the gestures should interact with each\u00a0other.</p>\n<p>Today, we are happy to announce the release of Gesture Handler 2.0. It brings an entirely new way of adding gesture-based interactions to your apps and addresses many shortcomings of the previous versions. Gesture Handler 2.0 comes with a new API designed from the ground up. We have spent a lot of time iterating over different concepts of defining gestures and we have settled on one that, in our opinion, makes creating complex gestures much easier. To make the transition to 2.0 more approachable for a huge gesture-handler user base, we are making this new release fully compatible with version 1 (all the APIs from version 1 stay the same). This way, you can upgrade your app even today and decide if and when it makes sense for you to start using the new API. In this post we highlight the key changes in the new API for you to get a sense of how it can help you improve your codebase, and how to take advantage of the new features.</p>\n<h4><strong>One to rule them\u00a0all</strong></h4>\n<p>One of the frequent use cases for our library is to monitor a number of concurrent gestures over a single view (e.g., pan, pinch, rotation of an image). To achieve this with the old API you\u2019d have to nest a number of gesture-specific components often interleaved with react-native\u2019s Views. In Gesture Handler 2 we are taking a different approach with a new GestureDetector component capable of recognizing all types of gestures.</p>\n<p>In the new API, gesture configuration is instantiated using the Gesture object and configured in the builder-like pattern, then passed to the detector component. Let\u2019s look at a simple example of a double\u00a0tap:</p>\n<a href=\"https://medium.com/media/d4f473dc9f7f9fa3920f95f16ed92dc4/href\">https://medium.com/media/d4f473dc9f7f9fa3920f95f16ed92dc4/href</a><p>That may not be very impressive but the improvement can be definitely seen when adding more than one gesture to a component. Instead of creating multiple handlers, and connecting them together using refs, we have introduced a new system of gesture composition.</p>\n<h4><strong>Composing gestures</strong></h4>\n<p>Along all the basic gestures, the Gesture object provides methods for composing gestures:</p>\n<ul>\n<li>Simultaneous\u200a\u2014\u200aall of the gestures can become active at the same\u00a0time.</li>\n<li>Race\u200a\u2014\u200athe first gesture that becomes active cancels other gestures.</li>\n<li>Exclusive\u200a\u2014\u200aassigns priority to the gestures: the first gesture can become active at any time, the second gesture can activate only when the first one fails, third gesture can activate only when the second one fails, and so\u00a0on.</li>\n</ul>\n<p>To demonstrate its capabilities let\u2019s look at a common example: pan, pinch and rotation on a single component.</p>\n<a href=\"https://medium.com/media/2ba5906f3ac385280412e96ca7e29eb2/href\">https://medium.com/media/2ba5906f3ac385280412e96ca7e29eb2/href</a><p>Another important improvement over the 1.0 API is that GestureDetector no longer needs to wrap an actual react-native View component. You can now put any composite component directly under GestureDetector, which helps with extracting gesture-related logic to separate files if that\u2019s the approach you prefer to\u00a0follow.</p>\n<h4><strong>Close integration with Reanimated 2</strong></h4>\n<p>Gesture Handler 2.0 is closely integrated with Reanimated 2. If both libraries are installed, functions set as callbacks to events will be automatically treated as Reanimated\u2019s worklets and GestureDetector will default to utilizing them for synchronous event delivery. Unfortunately, there is one trade off we had to make when designing this new API and it does no longer work with Reanimated 1 and with <a href=\"https://reactnative.dev/docs/animated#event\">React Native\u2019s Animated Events</a> (you could still use that approach via the old Gesture Handler API if you can\u2019t migrate to Reanimated 2 at the moment). One of the main reasons behind this decision is the fact that worklets allow for synchronous communication with the native code which brings us to the most important feature of this\u00a0release.</p>\n<h4><strong>Take full control of your\u00a0gestures</strong></h4>\n<p>We are introducing a new type of events in the Gesture Handler 2.0: touch events. They allow for tracking the position of individual fingers and decide from within the gesture\u2019s callback on when it should activate or fail. When used with the new <a href=\"https://docs.swmansion.com/react-native-gesture-handler/docs/manual-gestures/manual-gestures\">\u201cManual Gesture\u201d</a>, it\u2019s possible to implement almost any gesture recognition logic you may want in your app. This can be used, for example, to recognize users drawing some shapes, or making your pinch gesture only activate when the central point between the fingers is in a certain\u00a0place.</p>\n<p>We are also expanding on this idea and bringing it to the built-in gestures, making it possible to control the activation or failure criteria programmatically from within touch event callbacks as opposed to only having a set of configuration options for each gesture type. In order to use Manual Gesture you\u2019ll need to install Reanimated 2.3 or\u00a0newer.</p>\n<h4><strong>Compatibility with the old\u00a0API</strong></h4>\n<p>While we are going to focus on the new API going forward, the old one is not going away. Moreover, we made sure that it would be cross-compatible with the API introduced in 2.0, that includes specifying interactions between gestures so they can be made to work simultaneously or to wait for others. We are sure you\u2019ll love the new API, but if you don\u2019t want or can\u2019t move to it just yet you still can safely upgrade and take advantage of all the fixes and improvements to Gesture Handler core we are going to be adding to the future 2.x releases.</p>\n<p><em>New Gesture Handler is brought to you by </em><a href=\"https://swmansion.com/\"><em>Software Mansion</em></a><em> and\u00a0</em><a href=\"https://shopify.engineering/\"><em>Shopify</em></a><em>.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=50515f1c4afc\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/introducing-gesture-handler-2-0-50515f1c4afc\">Introducing Gesture Handler 2.0</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "react",
                "reanimated",
                "react-native"
            ]
        },
        {
            "title": "Experimenting with React Freeze",
            "pubDate": "2021-10-29 14:03:18",
            "link": "https://blog.swmansion.com/experimenting-with-react-freeze-71da578e2fa6?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/71da578e2fa6",
            "author": "Krzysztof Magiera",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*HXzJkXr5R85ibYULX-fx2g.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HXzJkXr5R85ibYULX-fx2g.png\"></figure><p>Today we are publishing a new React package\u200a\u2014\u200a<a href=\"https://github.com/software-mansion-labs/react-freeze\">react-freeze</a>. This tiny library uses the <a href=\"https://reactjs.org/docs/concurrent-mode-suspense.html\">React Suspense</a> mechanism to prevent parts of the react component tree from rendering while keeping its state (both react and native view / DOM element state) untouched. This way, it makes it possible to pause updates of parts of the app that are not visible to the user at the moment, and hence shave off some rendering time.</p>\n<p>The perfect use case for react-freeze library is navigation. When using stack navigation in React Native apps, there are a number of screen components that live in the react tree and can receive state updates, but are not visible to the user. Same applies to tab-based navigation in web or native apps\u200a\u2014\u200awe have some, potentially complex component trees rendered for each tab, and since we only see one tab at a moment the time spent on updating invisible tabs is\u00a0wasted.</p>\n<p>Note that react-freeze does not unmount frozen components, but they will be temporarily removed from the screen and replaced by a placeholder. This is a limitation of the approach we are taking with Suspense. However, this should not be a too problematic limitation as we normally aim to freeze only parts that are not visible\u00a0anyways.</p>\n<p><strong>This library is an experiment and even though we have tested it on a number of apps, we are still unsure if this approach is 100% right. If you are willing to try it and give us feedback there are few ways of doing\u00a0so:</strong></p>\n<h4>Using freeze library directly in React or React Native\u00a0apps:</h4>\n<p>In order to use freeze the only thing you need to do is to import Freeze component from react-freeze library you can install from npm. Then, you wrap some of your components with it and pass freeze={true} when you want the re-renders to be suspended in the wrapped\u00a0subtree:</p>\n<a href=\"https://medium.com/media/8d808d01f7bea0e5b6c50038471a4c46/href\">https://medium.com/media/8d808d01f7bea0e5b6c50038471a4c46/href</a><h4>Using it with react-navigation v5 or v6 (React\u00a0Native):</h4>\n<p>React-navigation uses a library called react-native-screens to render screen primitives. At the level of react-native-screens library we are able to tell which \u201cscreens\u201d are visible and which are hidden down the stack hierarchy. Thanks to that, we were able to modify react-native-screens library and add experimental support for freeze. In order to use it, the only thing you need to do is to upgrade react-native-screens to version 3.9.0 and add the below snippet in the root file of your application:</p>\n<a href=\"https://medium.com/media/8e1c5377fb3845b3107b9d75902a6e60/href\">https://medium.com/media/8e1c5377fb3845b3107b9d75902a6e60/href</a><p>This version of react-native-screens is compatible with react-navigation v5 and v6, however, with react-navigation v5 make sure to also have the screens library enabled. This can be done by calling an additional method in the main file of your application: enableScreens(true) and by passing the detachInactiveScreens option to your navigators (stack, tabs,\u00a0etc).</p>\n<h4>Where to go from\u00a0here?</h4>\n<p>If you are interested in learning more, visit the <a href=\"https://github.com/software-mansion-labs/react-freeze\">project page on Github</a>, star \u2b50\ufe0f the repo, and check out the\u00a0Readme!</p>\n<p><em>The work on React Native Open Source projects at </em><a href=\"https://swmansion.com/\"><em>Software Mansion</em></a><em> is sponsored by\u00a0</em><a href=\"https://engineering.shopify.com/\"><em>Shopify</em></a><em>.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=71da578e2fa6\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/experimenting-with-react-freeze-71da578e2fa6\">Experimenting with React Freeze</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HXzJkXr5R85ibYULX-fx2g.png\"></figure><p>Today we are publishing a new React package\u200a\u2014\u200a<a href=\"https://github.com/software-mansion-labs/react-freeze\">react-freeze</a>. This tiny library uses the <a href=\"https://reactjs.org/docs/concurrent-mode-suspense.html\">React Suspense</a> mechanism to prevent parts of the react component tree from rendering while keeping its state (both react and native view / DOM element state) untouched. This way, it makes it possible to pause updates of parts of the app that are not visible to the user at the moment, and hence shave off some rendering time.</p>\n<p>The perfect use case for react-freeze library is navigation. When using stack navigation in React Native apps, there are a number of screen components that live in the react tree and can receive state updates, but are not visible to the user. Same applies to tab-based navigation in web or native apps\u200a\u2014\u200awe have some, potentially complex component trees rendered for each tab, and since we only see one tab at a moment the time spent on updating invisible tabs is\u00a0wasted.</p>\n<p>Note that react-freeze does not unmount frozen components, but they will be temporarily removed from the screen and replaced by a placeholder. This is a limitation of the approach we are taking with Suspense. However, this should not be a too problematic limitation as we normally aim to freeze only parts that are not visible\u00a0anyways.</p>\n<p><strong>This library is an experiment and even though we have tested it on a number of apps, we are still unsure if this approach is 100% right. If you are willing to try it and give us feedback there are few ways of doing\u00a0so:</strong></p>\n<h4>Using freeze library directly in React or React Native\u00a0apps:</h4>\n<p>In order to use freeze the only thing you need to do is to import Freeze component from react-freeze library you can install from npm. Then, you wrap some of your components with it and pass freeze={true} when you want the re-renders to be suspended in the wrapped\u00a0subtree:</p>\n<a href=\"https://medium.com/media/8d808d01f7bea0e5b6c50038471a4c46/href\">https://medium.com/media/8d808d01f7bea0e5b6c50038471a4c46/href</a><h4>Using it with react-navigation v5 or v6 (React\u00a0Native):</h4>\n<p>React-navigation uses a library called react-native-screens to render screen primitives. At the level of react-native-screens library we are able to tell which \u201cscreens\u201d are visible and which are hidden down the stack hierarchy. Thanks to that, we were able to modify react-native-screens library and add experimental support for freeze. In order to use it, the only thing you need to do is to upgrade react-native-screens to version 3.9.0 and add the below snippet in the root file of your application:</p>\n<a href=\"https://medium.com/media/8e1c5377fb3845b3107b9d75902a6e60/href\">https://medium.com/media/8e1c5377fb3845b3107b9d75902a6e60/href</a><p>This version of react-native-screens is compatible with react-navigation v5 and v6, however, with react-navigation v5 make sure to also have the screens library enabled. This can be done by calling an additional method in the main file of your application: enableScreens(true) and by passing the detachInactiveScreens option to your navigators (stack, tabs,\u00a0etc).</p>\n<h4>Where to go from\u00a0here?</h4>\n<p>If you are interested in learning more, visit the <a href=\"https://github.com/software-mansion-labs/react-freeze\">project page on Github</a>, star \u2b50\ufe0f the repo, and check out the\u00a0Readme!</p>\n<p><em>The work on React Native Open Source projects at </em><a href=\"https://swmansion.com/\"><em>Software Mansion</em></a><em> is sponsored by\u00a0</em><a href=\"https://engineering.shopify.com/\"><em>Shopify</em></a><em>.</em></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=71da578e2fa6\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/experimenting-with-react-freeze-71da578e2fa6\">Experimenting with React Freeze</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "react-native",
                "react"
            ]
        },
        {
            "title": "Top 7 myths about Expo in 2021",
            "pubDate": "2021-10-05 07:54:16",
            "link": "https://blog.swmansion.com/top-7-myths-about-expo-in-2021-ee66f929bf9f?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/ee66f929bf9f",
            "author": "Bart\u0142omiej Klocek",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*iNLNgwPXatpA6YDng0j8MA.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iNLNgwPXatpA6YDng0j8MA.png\"></figure><p>2021 is a very exciting year for developers who use Expo to build their mobile apps. The <a href=\"https://medium.com/u/df61a4267d7a\">Expo</a> team with the assistance of the Software Mansion open-source team have been working hard on making React Native app development quicker and simpler; as a result of this progress, many statements on the web about what you can and can\u2019t do with Expo tools and services are no longer true. In this article, I\u2019m going to mention some most common myths and explain why they\u2019re no longer\u00a0true.</p>\n<h3>Myth #1: You have to choose between React Native and\u00a0Expo</h3>\n<p>When you open <a href=\"https://reactnative.dev/docs/environment-setup\">React Native installation docs</a>, you can see, that you can either start with <em>Expo CLI</em> and<em> React Native CLI</em>. It sounds like a difficult choice at the very beginning. When you choose Expo CLI, the setup process is much simpler, and you have all Expo SDK\u2019s features available out of the box. Choosing RN CLI would require a little more manual\u00a0work.</p>\n<p>In case you chose to start with Expo and then changed your mind or need some advanced features like custom native code/libraries that aren\u2019t included in the Expo SDK, there is always a door open\u200a\u2014\u200ayou can either <a href=\"https://docs.expo.dev/clients/introduction/\">build a custom development client</a> or \u201ceject\u201d into bare React Native workflow (while still being able to use Expo SDK libraries).</p>\n<p>Migration in the opposite direction is also possible\u200a\u2014\u200ayou can <a href=\"https://docs.expo.dev/bare/existing-apps/\">read more about it\u00a0here</a>.</p>\n<h3>Myth #2: Expo doesn\u2019t support custom native libraries</h3>\n<p>Have you ever found an awesome React Native library and found out that it doesn\u2019t work with Expo? Lack of support for third party native libraries was the biggest limitation of Expo managed workflow. You had to \u201ceject\u201d to bare workflow in order to be able to use custom native libraries.</p>\n<p>Now, this limitation applies only to the Expo Go app and Classic Builds. Since Expo SDK 42, you can build \u201c<a href=\"https://docs.expo.dev/clients/introduction/\">your own custom Expo Go</a>\u201d and include any native library you want. A custom client can be built either locally or in the cloud with EAS\u00a0Build.</p>\n<p>There are libraries requiring custom native configuration, e.g. modifying AndroidManifest.xml or Info.plist. Thanks to <a href=\"https://docs.expo.dev/guides/config-plugins/\">Expo Config Plugins</a>, they can be set up without touching any native code. Some libraries are already shipped with a config plugin included.</p>\n<h3>Myth #3: Ejecting is a very buggy and irreversible process</h3>\n<p>Fortunately, not anymore. The whole<em> \u2018ejecting\u2019</em> process has been revisited and heavily reworked. But why did the Expo team focus on polishing the \u201cquitting from Expo\u201d functionality? There is a couple of reasons. One is that it\u2019s used internally in EAS Build for building managed apps, and the other is that the Expo team changed their mindset over the last couple of years and consider managed and bare to both be first-class ways of using the\u00a0tools.</p>\n<p>To be clear, ejecting doesn\u2019t have to mean \u201cquitting\u201d. The expo eject command is only generating android and ios directories + index.js. When you delete them manually, you can eject again. Expo CLI has another command: expo prebuild which currently does the same, but it doesn\u2019t sound like it\u2019s a one-way\u00a0ticket.</p>\n<h3>Myth #4: Apps built with Expo are heavyweight</h3>\n<p>When we\u2019re talking about \u201cClassic Builds\u201d (expo build:[android|ios]), app size is one of the largest drawbacks. Every app built using expo build is actually a kind of the <em>Expo Go</em> app but modified to run only your app\u2019s JavaScript. It contains all Expo native SDK libraries, even those which you are not using in your\u00a0app.</p>\n<p>Why is it a myth then? Because Expo\u2019s new build service\u200a\u2014\u200a<a href=\"https://docs.expo.dev/build/introduction/\">EAS Build</a> solves this problem. When building a managed app, it <em>prebuilds</em> it first\u200a\u2014\u200aprepares native projects including only libraries specified in package.json.</p>\n<h3>Myth #5: Bare workflow / non-Expo apps cannot be built with\u00a0Expo</h3>\n<p>Yes and no. Classic Builds (expo build command) can build Expo managed apps only. But the new <a href=\"https://docs.expo.dev/build/introduction/\">EAS Build</a> service does not have such limitations and can build any React Native app, including Expo managed\u00a0ones.</p>\n<h3>Myth #6: Managed apps cannot be built\u00a0locally</h3>\n<p>Let\u2019s suppose you have created your app using Managed workflow and you were testing it in the Expo Go app. Now you want to build a standalone binary. At first glance, the expo build command is the only way to do this. But not everyone wants to upload their app\u2019s code to the cloud and wait until the build finishes. This is kind of a myth within a myth since you could always use <a href=\"https://github.com/expo/turtle-cli-example\">Turtle-CLI</a> to build locally\u00a0too.</p>\n<p>What if you want to build your managed app locally? You can use expo run:android or expo run:ios (if you have a Mac) commands. The only requirement is to have Android SDK / Xcode set up. Another option is to <a href=\"https://docs.expo.dev/build-reference/local-builds/\">run EAS Build locally</a> (eas build --local). The main difference compared to expo run is that it lets Expo handle the credentials management (app code signing etc.) for\u00a0you.</p>\n<h3>Myth #7: EAS Build is a paid-only service</h3>\n<blockquote>\n<strong>Update Nov 2021:</strong> EAS has a free tier now! Check out the <a href=\"https://blog.expo.dev/introducing-eas-395d4809cc6f\">announcement blog post here</a>.\u00a0\ud83c\udf89</blockquote>\n<p>As of writing this article, this one is actually true. Then why did I put it here? Many people think it is going to be paid-only forever. Fortunately, when looking at the <a href=\"https://expo.dev/pricing\">EAS Pricing page</a>, we can see that EAS Build is a <em>Preview feature </em>and there\u2019s a small asterisk sign\u00a0saying:</p>\n<blockquote>After graduating from preview, these services will be available under the free\u00a0plan.</blockquote>\n<p>The free tier is going to be similar to the current Classic Builds (expo build) tier. Finally, EAS Build is going to fully replace classic builds. When will EAS graduate from preview? I don\u2019t know, probably later this year. For now, you can have 1 month free to try EAS out. All you have to do is to sign up for the EAS Priority plan, then cancel your subscription before you get charged and if you don\u2019t have access to a credit card you can DM <a href=\"https://medium.com/@expo\">@expo</a> on Twitter to get\u00a0access.</p>\n<p>I hope this article explained some common myths about Expo. If you see any of these myths being perpetuated, feel free to put a link to this\u00a0article.</p>\n<ul>\n<li><a href=\"https://blog.expo.dev/introducing-custom-development-clients-5a2c79a9ddf8\">Introducing: Custom Development Clients</a></li>\n<li><a href=\"https://blog.expo.dev/expo-managed-workflow-in-2021-5b887bbf7dbb\">Expo managed workflow in 2021</a></li>\n<li><a href=\"https://blog.expo.dev/expo-managed-workflow-in-2021-d1c9b68aa10\">Expo managed workflow in 2021</a></li>\n<li><a href=\"https://blog.expo.dev/introducing-expo-run-commands-835ae8da4813\">Introducing: Expo Run Commands</a></li>\n<li><a href=\"https://docs.expo.dev/workflow/customizing/\">Adding custom native code - Expo Documentation</a></li>\n<li><a href=\"https://docs.expo.dev/build/introduction/\">EAS Build - Expo Documentation</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ee66f929bf9f\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/top-7-myths-about-expo-in-2021-ee66f929bf9f\">Top 7 myths about Expo in 2021</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*iNLNgwPXatpA6YDng0j8MA.png\"></figure><p>2021 is a very exciting year for developers who use Expo to build their mobile apps. The <a href=\"https://medium.com/u/df61a4267d7a\">Expo</a> team with the assistance of the Software Mansion open-source team have been working hard on making React Native app development quicker and simpler; as a result of this progress, many statements on the web about what you can and can\u2019t do with Expo tools and services are no longer true. In this article, I\u2019m going to mention some most common myths and explain why they\u2019re no longer\u00a0true.</p>\n<h3>Myth #1: You have to choose between React Native and\u00a0Expo</h3>\n<p>When you open <a href=\"https://reactnative.dev/docs/environment-setup\">React Native installation docs</a>, you can see, that you can either start with <em>Expo CLI</em> and<em> React Native CLI</em>. It sounds like a difficult choice at the very beginning. When you choose Expo CLI, the setup process is much simpler, and you have all Expo SDK\u2019s features available out of the box. Choosing RN CLI would require a little more manual\u00a0work.</p>\n<p>In case you chose to start with Expo and then changed your mind or need some advanced features like custom native code/libraries that aren\u2019t included in the Expo SDK, there is always a door open\u200a\u2014\u200ayou can either <a href=\"https://docs.expo.dev/clients/introduction/\">build a custom development client</a> or \u201ceject\u201d into bare React Native workflow (while still being able to use Expo SDK libraries).</p>\n<p>Migration in the opposite direction is also possible\u200a\u2014\u200ayou can <a href=\"https://docs.expo.dev/bare/existing-apps/\">read more about it\u00a0here</a>.</p>\n<h3>Myth #2: Expo doesn\u2019t support custom native libraries</h3>\n<p>Have you ever found an awesome React Native library and found out that it doesn\u2019t work with Expo? Lack of support for third party native libraries was the biggest limitation of Expo managed workflow. You had to \u201ceject\u201d to bare workflow in order to be able to use custom native libraries.</p>\n<p>Now, this limitation applies only to the Expo Go app and Classic Builds. Since Expo SDK 42, you can build \u201c<a href=\"https://docs.expo.dev/clients/introduction/\">your own custom Expo Go</a>\u201d and include any native library you want. A custom client can be built either locally or in the cloud with EAS\u00a0Build.</p>\n<p>There are libraries requiring custom native configuration, e.g. modifying AndroidManifest.xml or Info.plist. Thanks to <a href=\"https://docs.expo.dev/guides/config-plugins/\">Expo Config Plugins</a>, they can be set up without touching any native code. Some libraries are already shipped with a config plugin included.</p>\n<h3>Myth #3: Ejecting is a very buggy and irreversible process</h3>\n<p>Fortunately, not anymore. The whole<em> \u2018ejecting\u2019</em> process has been revisited and heavily reworked. But why did the Expo team focus on polishing the \u201cquitting from Expo\u201d functionality? There is a couple of reasons. One is that it\u2019s used internally in EAS Build for building managed apps, and the other is that the Expo team changed their mindset over the last couple of years and consider managed and bare to both be first-class ways of using the\u00a0tools.</p>\n<p>To be clear, ejecting doesn\u2019t have to mean \u201cquitting\u201d. The expo eject command is only generating android and ios directories + index.js. When you delete them manually, you can eject again. Expo CLI has another command: expo prebuild which currently does the same, but it doesn\u2019t sound like it\u2019s a one-way\u00a0ticket.</p>\n<h3>Myth #4: Apps built with Expo are heavyweight</h3>\n<p>When we\u2019re talking about \u201cClassic Builds\u201d (expo build:[android|ios]), app size is one of the largest drawbacks. Every app built using expo build is actually a kind of the <em>Expo Go</em> app but modified to run only your app\u2019s JavaScript. It contains all Expo native SDK libraries, even those which you are not using in your\u00a0app.</p>\n<p>Why is it a myth then? Because Expo\u2019s new build service\u200a\u2014\u200a<a href=\"https://docs.expo.dev/build/introduction/\">EAS Build</a> solves this problem. When building a managed app, it <em>prebuilds</em> it first\u200a\u2014\u200aprepares native projects including only libraries specified in package.json.</p>\n<h3>Myth #5: Bare workflow / non-Expo apps cannot be built with\u00a0Expo</h3>\n<p>Yes and no. Classic Builds (expo build command) can build Expo managed apps only. But the new <a href=\"https://docs.expo.dev/build/introduction/\">EAS Build</a> service does not have such limitations and can build any React Native app, including Expo managed\u00a0ones.</p>\n<h3>Myth #6: Managed apps cannot be built\u00a0locally</h3>\n<p>Let\u2019s suppose you have created your app using Managed workflow and you were testing it in the Expo Go app. Now you want to build a standalone binary. At first glance, the expo build command is the only way to do this. But not everyone wants to upload their app\u2019s code to the cloud and wait until the build finishes. This is kind of a myth within a myth since you could always use <a href=\"https://github.com/expo/turtle-cli-example\">Turtle-CLI</a> to build locally\u00a0too.</p>\n<p>What if you want to build your managed app locally? You can use expo run:android or expo run:ios (if you have a Mac) commands. The only requirement is to have Android SDK / Xcode set up. Another option is to <a href=\"https://docs.expo.dev/build-reference/local-builds/\">run EAS Build locally</a> (eas build --local). The main difference compared to expo run is that it lets Expo handle the credentials management (app code signing etc.) for\u00a0you.</p>\n<h3>Myth #7: EAS Build is a paid-only service</h3>\n<blockquote>\n<strong>Update Nov 2021:</strong> EAS has a free tier now! Check out the <a href=\"https://blog.expo.dev/introducing-eas-395d4809cc6f\">announcement blog post here</a>.\u00a0\ud83c\udf89</blockquote>\n<p>As of writing this article, this one is actually true. Then why did I put it here? Many people think it is going to be paid-only forever. Fortunately, when looking at the <a href=\"https://expo.dev/pricing\">EAS Pricing page</a>, we can see that EAS Build is a <em>Preview feature </em>and there\u2019s a small asterisk sign\u00a0saying:</p>\n<blockquote>After graduating from preview, these services will be available under the free\u00a0plan.</blockquote>\n<p>The free tier is going to be similar to the current Classic Builds (expo build) tier. Finally, EAS Build is going to fully replace classic builds. When will EAS graduate from preview? I don\u2019t know, probably later this year. For now, you can have 1 month free to try EAS out. All you have to do is to sign up for the EAS Priority plan, then cancel your subscription before you get charged and if you don\u2019t have access to a credit card you can DM <a href=\"https://medium.com/@expo\">@expo</a> on Twitter to get\u00a0access.</p>\n<p>I hope this article explained some common myths about Expo. If you see any of these myths being perpetuated, feel free to put a link to this\u00a0article.</p>\n<ul>\n<li><a href=\"https://blog.expo.dev/introducing-custom-development-clients-5a2c79a9ddf8\">Introducing: Custom Development Clients</a></li>\n<li><a href=\"https://blog.expo.dev/expo-managed-workflow-in-2021-5b887bbf7dbb\">Expo managed workflow in 2021</a></li>\n<li><a href=\"https://blog.expo.dev/expo-managed-workflow-in-2021-d1c9b68aa10\">Expo managed workflow in 2021</a></li>\n<li><a href=\"https://blog.expo.dev/introducing-expo-run-commands-835ae8da4813\">Introducing: Expo Run Commands</a></li>\n<li><a href=\"https://docs.expo.dev/workflow/customizing/\">Adding custom native code - Expo Documentation</a></li>\n<li><a href=\"https://docs.expo.dev/build/introduction/\">EAS Build - Expo Documentation</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ee66f929bf9f\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/top-7-myths-about-expo-in-2021-ee66f929bf9f\">Top 7 myths about Expo in 2021</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "react-native-development",
                "expo",
                "expo-cli",
                "react-native",
                "eas-build"
            ]
        },
        {
            "title": "Building Reigns: How to reign over mobile game development using Reanimated 2. Pa",
            "pubDate": "2021-06-21 09:13:59",
            "link": "https://blog.swmansion.com/building-reigns-how-to-reign-over-mobile-game-development-using-reanimated-2-pa-55ae2017df50?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/55ae2017df50",
            "author": "Wojciech Stanisz",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*7O1GFTCWd_2MlAwgznarBw.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7O1GFTCWd_2MlAwgznarBw.png\"></figure><h3>Building Reigns: How to reign over mobile game development using Reanimated 2. Part\u00a03</h3>\n<p>This is the last post in a series dedicated to building a clone of Reigns game in React Native using Reanimated 2 and Gesture Handler. If you haven\u2019t seen the first two parts you can find part one where we implemented the gesture handler <a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">here</a> and the second part where we focus mostly on the animations <a href=\"https://blog.swmansion.com/building-reigns-how-to-strengthen-reign-over-mobile-game-development-using-reanimated-2-66c127a210e9\">here</a>. Our last meeting will finalize our project by adding game logic, show questions, and making the initial animation.</p>\n<p>Like in the previous articles, you can find the code in the Github repository that you can visit by clicking the iteration link next to the title of each\u00a0chapter.</p>\n<h3>Add basic logic\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-6\">iteration-6</a>\n</h3>\n<p>The time has come. Our creation will be alive! (At least a little\u00a0bit).</p>\n<p>In order to make the game playable, we need to determine when the player makes a decision by swinging the card to the side of the screen. To do so, we will use two metrics: velocity and position.</p>\n<p>By combining the current position and multiplying velocity by a given time (in this example it will be 0.2 sec) we can simulate toss and see where the released element is going to land. Based on this information we can decide if the player made a decision by moving the card to any side of the screen or should it return to the deck on the center of the\u00a0screen.</p>\n<p>To make such recognition possible we have to modify the gestureHandler (created in <em>iteration-1).</em></p>\n<p>Conditional statements are pretty simple here. The one thing you should know about them is that there are different useful pieces of information inside the event object, for example: velocity. What\u2019s more interesting is the runOnJS function with quite a distinct syntax. This strange line of code lets us call JS functions inside Reanimated\u2019s code block. In this case, we don\u2019t pass any prop to our function but instead, this syntax allows us to pass props to the function using second brackets\u00a0like:</p>\n<p>runOnJS(func)(prop1, prop2);</p>\n<p>An important note here: You shouldn\u2019t try to run JS functions declared outside reanimated code blocks inside it without\u00a0runOnJS.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/606/0*JNaF9sYPL5ulhbcW\"><figcaption><em>Upgraded onEnd handler in useAnimatedGestureHandler created\u00a0earlier.</em></figcaption></figure><p>Worth noting here is that you should always pass velocity to the withSpring hook to keep smooth and persistent animation.</p>\n<p>The actual handler lives in the <em>Screen.js</em> file and is passed to the Card via\u00a0prop.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/484/0*vwJljTppYIRj8kcJ\"></figure><p>Handler sets the showCard flag to false to remove the old card loads the next card data and switches the flag to show it again. Each time Card gets a new date, it fires flip animation. This way, every new card is shown in a smooth, animated\u00a0manner.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/474/0*1jUc7nGd-GsElYwH\"><figcaption><em>useEffect used to control basic logic of the application.</em></figcaption></figure><p>As you can see there is also a small trick here. The card is rendered and then flipped, but only after 200 milliseconds await.</p>\n<p>What\u2019s worth noting here is using the new withDelay hook. This is a simple hook that will delay the start of an animation by a given time. This is a really simple way to make sure all data in the front of the card (like avatar picture) actually managed to load and show up, without any visual glitches. There should be some more advanced logic but I didn\u2019t want to add unnecessary complexity to an already big\u00a0example.</p>\n<p>To make the card active after the end of animation I used the animation callback of withTiming function. You can read more about it\u00a0<a href=\"https://docs.swmansion.com/react-native-reanimated/docs/api/withTiming/#callback-functionoptional\">here</a>.</p>\n<h3>Start game animation\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-7\">iteration-7</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/1*3eOWYdmsN5FQbujr5fEzAw.gif\"><figcaption><em>Result of iteration-7 code.</em></figcaption></figure><p>At this stage, we should make a couple of animated cards slide into the welcome screen of the game. To do so, we need to import them in the <em>Screen.js </em>file like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*5IaRnI7dUdbWLDCg\"></figure><p>As you can see, I created separate Static and Animated reverse cards. That\u2019s because we need one reversed card always on the bottom to simulate the deck. But since we animate 5 different cards into the screen, it would be a waste to keep all 5 of them on the screen for the rest of the game, if we are not going to use them anymore. Following that logic, we have separate components for animated cards, and one separate for the static card that will stay on the screen for the rest of the\u00a0game.</p>\n<p>Let\u2019s take a closer look at the animated card, shall\u00a0we?</p>\n<p>Previously, using Animated.View we created a separate animatedStyle for each card. It worked because each style was unique. But now, since we need to create a couple of components with the exact same styles and the only difference will be timing it will be better to automatize it somehow.\u00a0How?</p>\n<p>The answer is: \u2018worklet\u2019.</p>\n<p>Let\u2019s take a look at Card in <em>PlaceholderBackCards.js</em>. As you can see, I used useAnimatedStyle in a little different manner here. Instead of passing an object that contains static useAnimatedStyle inside, I used the useAnimatedStyle hook to wrap the function that will get the\u00a0index.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/706/0*myBTP0LTWRCbrZnB\"></figure><p>cardTransform function is a \u2018worklet\u2019. That means we can use it in Reanimated 2 code. This way I can pass an index and make a small adjustment in style based on a given variable.</p>\n<p>What\u2019s worth noting here is using the withDelay hook. In my case, the delay itself is calculated based on the passed\u00a0index.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/593/0*1WIU-uU5KYrd2zg6\"></figure><h3>Animated questions\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-8\">iteration-8</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/0*jrtgCCPSqr38NC0B\"><figcaption><em>Result of iteration-8 code.</em></figcaption></figure><p>Question time!</p>\n<p>First things first, let\u2019s add the question component to the main render. As you can see the component is not shown conditionally this time. The visibility of the component will be controlled by showQuestion flag passed as a prop to the component.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/653/0*NYTfWGLOVJP_3Euz\"></figure><p>This time we don\u2019t need to create any shared values or create any useEffect to handle our animation. If your animations are really simple and need to be performed once the props change you can simply put them straight into the useAnimatedStyle and calculate them directly inside the returned style\u00a0object.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/590/0*23nYWEA0QxwJWqHi\"></figure><p>Lastly, we have to use our new animatedWrapper, as a style for Animated.View and we are\u00a0done!</p>\n<p>Viola! That was\u00a0<strong>fast</strong>!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/611/0*BCcTm4VJwf0sIj8h\"></figure><h3>Animated elements: final touch\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-9\">iteration-9</a>\n</h3>\n<p>Final iteration!</p>\n<p>Time for an ultimate\u00a0trial!</p>\n<p>This time it\u2019s gonna be different. I won\u2019t describe each step. This time <strong><em>YOU </em></strong>will do it yourself. If you followed all the previous steps I\u2019m pretty sure you can do it. I haven\u2019t used any new technique or API so figuring out what happened in the last iteration will be a pretty good exercise. Good\u00a0luck!</p>\n<p>I strongly recommend looking for new things in <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/Screen.js\"><em>Screen.js</em></a><em> </em>and finding new components there.</p>\n<p>But if you don\u2019t feel like trying today and just wanna see how the last iteration looks like, and how it works, here\u2019s part for\u00a0you:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*ewEKnGzTJ9uc9rhSfvBuCA.gif\"><figcaption><em>Result of the final iteration</em></figcaption></figure><p>In <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/Screen.js\"><em>Screen.js</em></a><em> </em>you can find a new PowerIndicators component with currentMood prop. currentMood is an object containing two arrays: happy and sad containing info on who should be amazed by the player\u2019s answer and who should be enraged. Those arrays are set in the handlers of left and right\u00a0answers.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/626/0*KrZ6FQFdJH94q_l2\"></figure><p>currentMood property is processed in the <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/PowerIndicators.js\"><em>PowerIndicators.js</em></a> to get info about each person and push it as a prop to the next components in which we are checking if the selected person should react to the current action and handle this information in <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/PowerPerson.js\"><em>PowerPerson.js</em></a><em> </em>file by firing suitable animation. In case somebody is happy with the player\u2019s answer it\u2019s gonna be a heart, and in case somebody is not in fond of the action it\u2019s a rainy\u00a0cloud.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/1*wAD4doErLVvLXcln1_Zc9w.png\"><figcaption>Power person mood animations.</figcaption></figure><p>In the return statement, we can see that the heart and cloud images are hardcoded and the only thing that is changing are the styles of the animated\u00a0wrapper.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/701/0*MlPHuJiODG_6a_B8\"></figure><p>That\u2019s it. Whole application. What a\u00a0journey!</p>\n<h3>Time to steal some\u00a0hearts!</h3>\n<p>Now you know it all. You are ready to make the best animations out there with brand new, cutting-edge technology! If you want to learn more you can always read the<a href=\"https://docs.swmansion.com/react-native-reanimated/docs/\"> official documentation</a> or read about the library itself<a href=\"https://blog.swmansion.com/reanimated-2-0-stable-release-is-out-564c9c910891\">\u00a0here</a>.</p>\n<p>The possibilities are endless! You can create games, apps, try to recreate your old project, or enhance existing react-native ones! Time to steal the hearts of your\u00a0users!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=55ae2017df50\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/building-reigns-how-to-reign-over-mobile-game-development-using-reanimated-2-pa-55ae2017df50\">Building Reigns: How to reign over mobile game development using Reanimated 2. Pa</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*7O1GFTCWd_2MlAwgznarBw.png\"></figure><h3>Building Reigns: How to reign over mobile game development using Reanimated 2. Part\u00a03</h3>\n<p>This is the last post in a series dedicated to building a clone of Reigns game in React Native using Reanimated 2 and Gesture Handler. If you haven\u2019t seen the first two parts you can find part one where we implemented the gesture handler <a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">here</a> and the second part where we focus mostly on the animations <a href=\"https://blog.swmansion.com/building-reigns-how-to-strengthen-reign-over-mobile-game-development-using-reanimated-2-66c127a210e9\">here</a>. Our last meeting will finalize our project by adding game logic, show questions, and making the initial animation.</p>\n<p>Like in the previous articles, you can find the code in the Github repository that you can visit by clicking the iteration link next to the title of each\u00a0chapter.</p>\n<h3>Add basic logic\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-6\">iteration-6</a>\n</h3>\n<p>The time has come. Our creation will be alive! (At least a little\u00a0bit).</p>\n<p>In order to make the game playable, we need to determine when the player makes a decision by swinging the card to the side of the screen. To do so, we will use two metrics: velocity and position.</p>\n<p>By combining the current position and multiplying velocity by a given time (in this example it will be 0.2 sec) we can simulate toss and see where the released element is going to land. Based on this information we can decide if the player made a decision by moving the card to any side of the screen or should it return to the deck on the center of the\u00a0screen.</p>\n<p>To make such recognition possible we have to modify the gestureHandler (created in <em>iteration-1).</em></p>\n<p>Conditional statements are pretty simple here. The one thing you should know about them is that there are different useful pieces of information inside the event object, for example: velocity. What\u2019s more interesting is the runOnJS function with quite a distinct syntax. This strange line of code lets us call JS functions inside Reanimated\u2019s code block. In this case, we don\u2019t pass any prop to our function but instead, this syntax allows us to pass props to the function using second brackets\u00a0like:</p>\n<p>runOnJS(func)(prop1, prop2);</p>\n<p>An important note here: You shouldn\u2019t try to run JS functions declared outside reanimated code blocks inside it without\u00a0runOnJS.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/606/0*JNaF9sYPL5ulhbcW\"><figcaption><em>Upgraded onEnd handler in useAnimatedGestureHandler created\u00a0earlier.</em></figcaption></figure><p>Worth noting here is that you should always pass velocity to the withSpring hook to keep smooth and persistent animation.</p>\n<p>The actual handler lives in the <em>Screen.js</em> file and is passed to the Card via\u00a0prop.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/484/0*vwJljTppYIRj8kcJ\"></figure><p>Handler sets the showCard flag to false to remove the old card loads the next card data and switches the flag to show it again. Each time Card gets a new date, it fires flip animation. This way, every new card is shown in a smooth, animated\u00a0manner.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/474/0*1jUc7nGd-GsElYwH\"><figcaption><em>useEffect used to control basic logic of the application.</em></figcaption></figure><p>As you can see there is also a small trick here. The card is rendered and then flipped, but only after 200 milliseconds await.</p>\n<p>What\u2019s worth noting here is using the new withDelay hook. This is a simple hook that will delay the start of an animation by a given time. This is a really simple way to make sure all data in the front of the card (like avatar picture) actually managed to load and show up, without any visual glitches. There should be some more advanced logic but I didn\u2019t want to add unnecessary complexity to an already big\u00a0example.</p>\n<p>To make the card active after the end of animation I used the animation callback of withTiming function. You can read more about it\u00a0<a href=\"https://docs.swmansion.com/react-native-reanimated/docs/api/withTiming/#callback-functionoptional\">here</a>.</p>\n<h3>Start game animation\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-7\">iteration-7</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/1*3eOWYdmsN5FQbujr5fEzAw.gif\"><figcaption><em>Result of iteration-7 code.</em></figcaption></figure><p>At this stage, we should make a couple of animated cards slide into the welcome screen of the game. To do so, we need to import them in the <em>Screen.js </em>file like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*5IaRnI7dUdbWLDCg\"></figure><p>As you can see, I created separate Static and Animated reverse cards. That\u2019s because we need one reversed card always on the bottom to simulate the deck. But since we animate 5 different cards into the screen, it would be a waste to keep all 5 of them on the screen for the rest of the game, if we are not going to use them anymore. Following that logic, we have separate components for animated cards, and one separate for the static card that will stay on the screen for the rest of the\u00a0game.</p>\n<p>Let\u2019s take a closer look at the animated card, shall\u00a0we?</p>\n<p>Previously, using Animated.View we created a separate animatedStyle for each card. It worked because each style was unique. But now, since we need to create a couple of components with the exact same styles and the only difference will be timing it will be better to automatize it somehow.\u00a0How?</p>\n<p>The answer is: \u2018worklet\u2019.</p>\n<p>Let\u2019s take a look at Card in <em>PlaceholderBackCards.js</em>. As you can see, I used useAnimatedStyle in a little different manner here. Instead of passing an object that contains static useAnimatedStyle inside, I used the useAnimatedStyle hook to wrap the function that will get the\u00a0index.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/706/0*myBTP0LTWRCbrZnB\"></figure><p>cardTransform function is a \u2018worklet\u2019. That means we can use it in Reanimated 2 code. This way I can pass an index and make a small adjustment in style based on a given variable.</p>\n<p>What\u2019s worth noting here is using the withDelay hook. In my case, the delay itself is calculated based on the passed\u00a0index.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/593/0*1WIU-uU5KYrd2zg6\"></figure><h3>Animated questions\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-8\">iteration-8</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/0*jrtgCCPSqr38NC0B\"><figcaption><em>Result of iteration-8 code.</em></figcaption></figure><p>Question time!</p>\n<p>First things first, let\u2019s add the question component to the main render. As you can see the component is not shown conditionally this time. The visibility of the component will be controlled by showQuestion flag passed as a prop to the component.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/653/0*NYTfWGLOVJP_3Euz\"></figure><p>This time we don\u2019t need to create any shared values or create any useEffect to handle our animation. If your animations are really simple and need to be performed once the props change you can simply put them straight into the useAnimatedStyle and calculate them directly inside the returned style\u00a0object.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/590/0*23nYWEA0QxwJWqHi\"></figure><p>Lastly, we have to use our new animatedWrapper, as a style for Animated.View and we are\u00a0done!</p>\n<p>Viola! That was\u00a0<strong>fast</strong>!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/611/0*BCcTm4VJwf0sIj8h\"></figure><h3>Animated elements: final touch\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-9\">iteration-9</a>\n</h3>\n<p>Final iteration!</p>\n<p>Time for an ultimate\u00a0trial!</p>\n<p>This time it\u2019s gonna be different. I won\u2019t describe each step. This time <strong><em>YOU </em></strong>will do it yourself. If you followed all the previous steps I\u2019m pretty sure you can do it. I haven\u2019t used any new technique or API so figuring out what happened in the last iteration will be a pretty good exercise. Good\u00a0luck!</p>\n<p>I strongly recommend looking for new things in <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/Screen.js\"><em>Screen.js</em></a><em> </em>and finding new components there.</p>\n<p>But if you don\u2019t feel like trying today and just wanna see how the last iteration looks like, and how it works, here\u2019s part for\u00a0you:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*ewEKnGzTJ9uc9rhSfvBuCA.gif\"><figcaption><em>Result of the final iteration</em></figcaption></figure><p>In <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/Screen.js\"><em>Screen.js</em></a><em> </em>you can find a new PowerIndicators component with currentMood prop. currentMood is an object containing two arrays: happy and sad containing info on who should be amazed by the player\u2019s answer and who should be enraged. Those arrays are set in the handlers of left and right\u00a0answers.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/626/0*KrZ6FQFdJH94q_l2\"></figure><p>currentMood property is processed in the <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/PowerIndicators.js\"><em>PowerIndicators.js</em></a> to get info about each person and push it as a prop to the next components in which we are checking if the selected person should react to the current action and handle this information in <a href=\"https://github.com/wojtus7/reanimated-story-cards/blob/iteration-9/PowerPerson.js\"><em>PowerPerson.js</em></a><em> </em>file by firing suitable animation. In case somebody is happy with the player\u2019s answer it\u2019s gonna be a heart, and in case somebody is not in fond of the action it\u2019s a rainy\u00a0cloud.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/473/1*wAD4doErLVvLXcln1_Zc9w.png\"><figcaption>Power person mood animations.</figcaption></figure><p>In the return statement, we can see that the heart and cloud images are hardcoded and the only thing that is changing are the styles of the animated\u00a0wrapper.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/701/0*MlPHuJiODG_6a_B8\"></figure><p>That\u2019s it. Whole application. What a\u00a0journey!</p>\n<h3>Time to steal some\u00a0hearts!</h3>\n<p>Now you know it all. You are ready to make the best animations out there with brand new, cutting-edge technology! If you want to learn more you can always read the<a href=\"https://docs.swmansion.com/react-native-reanimated/docs/\"> official documentation</a> or read about the library itself<a href=\"https://blog.swmansion.com/reanimated-2-0-stable-release-is-out-564c9c910891\">\u00a0here</a>.</p>\n<p>The possibilities are endless! You can create games, apps, try to recreate your old project, or enhance existing react-native ones! Time to steal the hearts of your\u00a0users!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=55ae2017df50\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/building-reigns-how-to-reign-over-mobile-game-development-using-reanimated-2-pa-55ae2017df50\">Building Reigns: How to reign over mobile game development using Reanimated 2. Pa</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "reanimated",
                "react-native",
                "mobile-games"
            ]
        },
        {
            "title": "Building Reigns: How to strengthen reign over mobile game development using Reanimated 2.",
            "pubDate": "2021-05-27 09:18:42",
            "link": "https://blog.swmansion.com/building-reigns-how-to-strengthen-reign-over-mobile-game-development-using-reanimated-2-66c127a210e9?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/66c127a210e9",
            "author": "Wojciech Stanisz",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*nKeEnkHA1HlOxopKk8Moiw.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nKeEnkHA1HlOxopKk8Moiw.png\"></figure><p>This is the second post in a series dedicated to building a clone of Reigns game in React Native using Reanimated 2 and Gesture Handler. If you haven\u2019t seen the first part where we focused on the gesture handling implementation you can find it <a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">here</a>. This time around we are going to focus more on the visuals. We\u2019ll create dynamic text and flip animations, imitate shadows, and put graphics to make our card look\u00a0superb!</p>\n<p>Like in the previous article you can find the code in the Github repository that you can visit by clicking the iteration link next to the title of each\u00a0chapter.</p>\n<h3>Animated text\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-2\">iteration-2</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/0*8YO8FLLpieVXgSpj\"><figcaption><em>Result of iteration-2 code.</em></figcaption></figure><p>As the very first step of this part of the tutorial, we are going to add text to our card that reacts to its transition in the following manner: it will show the right option only when the card is moved a little to the right and the left option only when the card is swiped to the\u00a0left.</p>\n<p>The new render looks something like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dyKF8K3tLyfW-e-N\"></figure><p>As you can see there are two new separate text wrappers (highlighted blue and green) instead of one conditional text render\u00a0like:</p>\n<pre>&lt;Animated.Text&gt;<br>  {x.value &gt; 0 ? rightText : leftText}<br>&lt;/Animated.Text&gt;</pre>\n<p>We have to remember that it\u2019s not that simple to use shared value in code. We can\u2019t use it simply in the code even if the component itself is Animated.View or Animated.Text. If we really wanted to make only one text wrapper we should use the useAnimatedProps hook (you can read about it <a href=\"https://docs.swmansion.com/react-native-reanimated/docs/api/useAnimatedProps/\">here</a>), but for simplicity in this example we always render two separate components and animate their opacity based on the card\u2019s movement.</p>\n<p>The second thing that you may notice is that each animated text wrapper got some separate animatedSideTextWrapper style assigned to it. Those style objects look almost the same with the small exception that the interpolator got opposite input values. An example for the right wrapper looks like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/658/0*CgHHDcilxyZ2b5E6\"><figcaption><em>Right text wrapper\u2019s style.</em></figcaption></figure><p>The last thing worth noting in this step is topTextWrapper style object because the values assigned are a little odd at a first\u00a0glance.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/430/0*-UFwqeCl5qoppMXX\"></figure><p>Interesting values here are width\u00a0, left and right\u00a0. The simple explanation for them would be that we want to rotate one component inside a different component and that\u2019s really troublesome. I think there\u2019s no use in explaining in words something that you can understand with only one\u00a0picture:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/430/0*4TqzO8D5xD9x81-8\"><figcaption><em>Broken card\u00a0styles.</em></figcaption></figure><p>To solve the problem we can just create a component a little too big so the rotation won\u2019t expose the boundaries, just like we did in the styles\u00a0above.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/426/0*xKAShTgk9L6F79-W\"><figcaption><em>Card after fixing the\u00a0styles.</em></figcaption></figure><h3>Flip animation\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-3\">iteration-3</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/406/0*02XzPZpZzb9x7Ylf\"><figcaption><em>Result of iteration-3 code.</em></figcaption></figure><p>A very important part of Reigns is showing the next cardin a smooth deck-like manner. To make animation possible we will add a new wrapper that contains the whole card and rotate it accordingly.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*CnHB_qBUqTboW22G\"></figure><p>Theoretically, we could use Animated.View located directly below to get only one Animated.View responsible for both animation but since it\u2019s used to animate finger movement I wanted to keep it as simple and as clear as possible. I did this by keeping the single responsibility for each Animated.View,so we get a separate View to turn the card around and to move it around using gestures.</p>\n<p>To rotate our card we will need a new shared value. Just to keep learning something new our new value will start with initial value\u00a01.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/388/0*7VbDByOQ6YxVh96u\"><figcaption><em>New shared value initialization.</em></figcaption></figure><p>Now\u2019s the time to use it. Let\u2019s use the useAnimatedStyle. Inside we can see three props changed based on openAnimation shared value: scale, perspective, and\u00a0rotateY.</p>\n<p>The only necessary change is rotateY moved by 180 degrees but scale and perspective are making the animation so much prettier! You can try to tweak all those values to see how it changes the\u00a0look!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/652/0*kSjrseS07GqHTg8A\"><figcaption><em>Style logic controlling our card\u2019s flip animation.</em></figcaption></figure><p>Movement shared values like x and y are controlled by gesture handler. This time we would rather flip the card by using a trigger inside the code. That\u2019s why I added a new button that controls the openAnimation shared value. It should be animated from initial 1 to 2 and back again. This time around we can use a new function: instead of withSpring\u200a\u2014\u200athat we are already familiar with\u200a\u2014\u200awe can use new withTiming.</p>\n<p>It works almost the same as withSpring but this time around it\u2019s not calculated based on physics values, but it\u2019s based on some predefined bezier curve the animation will follow. All animation adjustments can be set in the config object, but in my case, I only adjusted the duration of the animation to make it a little longer than the default\u00a0value.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/675/0*SjjRuUsdf7nSnN__\"><figcaption><em>Pressing this button will flip the\u00a0card.</em></figcaption></figure><h3>Creating card\u2019s front and back\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-4\">iteration-4</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/381/0*9S4omDaULckBtewE\"><figcaption><em>Result of iteration-4 code.</em></figcaption></figure><p>This step\u2019s gonna be\u00a0easy!</p>\n<p>This time around the only thing we add is just some graphics for the card front and reverse. For that reason, in our render method, we can find new <em>CardPerson.js</em> and <em>CardReverse.js</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*6Ur0VOrTY8IC4Wk7\"></figure><p>But\u2026we can\u2019t just simply add them. We also need to write a logic that will determine when to show the card and which side of the card should be presented. Since we know the card flip animation is based on openAnimation shared value that travels between values 1 and 2, we can safely assume we should stop rendering the reverse just in the middle when the value exceeds\u00a01.5.</p>\n<p>For that reason, we can add a new opacity prop to previously created animatedFront style, that will switch whenever the value exceeds 1.5\u00a0.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*p-h9Rlim5HyBQsLD\"></figure><p>And very similar animatedBack style but with reversed\u00a0values:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/649/0*99NB8OVb2WPdOboO\"></figure><h3>Animated shadows\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-5\">iteration-5</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/412/0*nVV2yTUk3MfHUu6k\"><figcaption><em>Result of iteration-5 code.</em></figcaption></figure><p>Adding shadows will bring some additional depth to our animation. It\u2019s a simple, yet effective trick to add some depth to any 3D animation. I\u2019m totally aware this trick won\u2019t work in all cases, but adding it on a simple 2D plane can be a breeze using the new Reanimated.</p>\n<p>First things first, we need to update our render. To keep the single responsibility rule introduced earlier I decided to create two new Animated.View\u200a\u2014\u200aone for each side of the\u00a0card.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*hV8jUqEccucHwkVU\"><figcaption><em>New shadow components added to our render\u00a0method.</em></figcaption></figure><p>The trick here is to use position: absolute combined with relatively high zIndex and size spread over the whole component so the shadow would cover the component but won\u2019t infringe the internal flow while covering\u00a0it.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/349/0*HaT3uh2wQX2J_kc3\"><figcaption><em>Shadow basic\u00a0styles.</em></figcaption></figure><p>Finally, we can connect it with our openAnimation shared value. If you have a really sharp eye you can spot I used Extrapolate.CLAMP instead Extrapolate.EXTEND in the interpolation function. That\u2019s because I didn\u2019t want the opacity value to wander around out of control. CLAMP will keep the last given value and won\u2019t extrapolate it further. It makes sure that the opacity will never go below 0 or above 1. If that ever happened, it would have a disastrous effect: the react-native component would be confused, and every value not in range between 0 and 1 would return just 1. That means strange visual glitches out of our\u00a0control.</p>\n<p>NOT EPIC.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/550/0*cRKcqgWmTdqLNkv2\"><figcaption><em>Shadow animated\u00a0styles.</em></figcaption></figure><h3>We\u2019ve done a\u00a0lot!</h3>\n<p>We are almost done with work around our card. It looks amazing isn\u2019t it? During our journey we used a lot of different tools around reanimated 2 and I hope you are getting familiar with\u00a0it!</p>\n<p>Can you see the schema\u00a0already?</p>\n<p>First, we create shared we can\u00a0use:</p>\n<pre>const mySharedValue = useSharedValue(0);</pre>\n<p>Then we start creating Animated.View with useAnimatedStyle object\u00a0inside:</p>\n<pre>&lt;Animated.View style={animatedStyle} /&gt;</pre>\n<p>Created useAnimatedStyle always use some sharedValue to calculate new\u00a0style:</p>\n<pre>const animatedFront = useAnimatedStyle(() =&gt; {<br>  return {<br>    height: mySharedValue.value,<br>  };<br>});</pre>\n<p>And finally, we use some reanimated mechanism like withTiming or withSpring to animate\u00a0it:</p>\n<pre>mySharedValue.value = withTiming(100);</pre>\n<p>You are a quick learner!\u00a0\ud83d\udc4f</p>\n<p>Next time we will make the application alive by creating basic game logic to control the whole experience, start menu and loading animation! It\u2019s also gonna be the last part of our journey so stay tuned and see you\u00a0soon!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=66c127a210e9\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/building-reigns-how-to-strengthen-reign-over-mobile-game-development-using-reanimated-2-66c127a210e9\">Building Reigns: How to strengthen reign over mobile game development using Reanimated 2.</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*nKeEnkHA1HlOxopKk8Moiw.png\"></figure><p>This is the second post in a series dedicated to building a clone of Reigns game in React Native using Reanimated 2 and Gesture Handler. If you haven\u2019t seen the first part where we focused on the gesture handling implementation you can find it <a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">here</a>. This time around we are going to focus more on the visuals. We\u2019ll create dynamic text and flip animations, imitate shadows, and put graphics to make our card look\u00a0superb!</p>\n<p>Like in the previous article you can find the code in the Github repository that you can visit by clicking the iteration link next to the title of each\u00a0chapter.</p>\n<h3>Animated text\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-2\">iteration-2</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/401/0*8YO8FLLpieVXgSpj\"><figcaption><em>Result of iteration-2 code.</em></figcaption></figure><p>As the very first step of this part of the tutorial, we are going to add text to our card that reacts to its transition in the following manner: it will show the right option only when the card is moved a little to the right and the left option only when the card is swiped to the\u00a0left.</p>\n<p>The new render looks something like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dyKF8K3tLyfW-e-N\"></figure><p>As you can see there are two new separate text wrappers (highlighted blue and green) instead of one conditional text render\u00a0like:</p>\n<pre>&lt;Animated.Text&gt;<br>  {x.value &gt; 0 ? rightText : leftText}<br>&lt;/Animated.Text&gt;</pre>\n<p>We have to remember that it\u2019s not that simple to use shared value in code. We can\u2019t use it simply in the code even if the component itself is Animated.View or Animated.Text. If we really wanted to make only one text wrapper we should use the useAnimatedProps hook (you can read about it <a href=\"https://docs.swmansion.com/react-native-reanimated/docs/api/useAnimatedProps/\">here</a>), but for simplicity in this example we always render two separate components and animate their opacity based on the card\u2019s movement.</p>\n<p>The second thing that you may notice is that each animated text wrapper got some separate animatedSideTextWrapper style assigned to it. Those style objects look almost the same with the small exception that the interpolator got opposite input values. An example for the right wrapper looks like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/658/0*CgHHDcilxyZ2b5E6\"><figcaption><em>Right text wrapper\u2019s style.</em></figcaption></figure><p>The last thing worth noting in this step is topTextWrapper style object because the values assigned are a little odd at a first\u00a0glance.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/430/0*-UFwqeCl5qoppMXX\"></figure><p>Interesting values here are width\u00a0, left and right\u00a0. The simple explanation for them would be that we want to rotate one component inside a different component and that\u2019s really troublesome. I think there\u2019s no use in explaining in words something that you can understand with only one\u00a0picture:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/430/0*4TqzO8D5xD9x81-8\"><figcaption><em>Broken card\u00a0styles.</em></figcaption></figure><p>To solve the problem we can just create a component a little too big so the rotation won\u2019t expose the boundaries, just like we did in the styles\u00a0above.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/426/0*xKAShTgk9L6F79-W\"><figcaption><em>Card after fixing the\u00a0styles.</em></figcaption></figure><h3>Flip animation\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-3\">iteration-3</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/406/0*02XzPZpZzb9x7Ylf\"><figcaption><em>Result of iteration-3 code.</em></figcaption></figure><p>A very important part of Reigns is showing the next cardin a smooth deck-like manner. To make animation possible we will add a new wrapper that contains the whole card and rotate it accordingly.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*CnHB_qBUqTboW22G\"></figure><p>Theoretically, we could use Animated.View located directly below to get only one Animated.View responsible for both animation but since it\u2019s used to animate finger movement I wanted to keep it as simple and as clear as possible. I did this by keeping the single responsibility for each Animated.View,so we get a separate View to turn the card around and to move it around using gestures.</p>\n<p>To rotate our card we will need a new shared value. Just to keep learning something new our new value will start with initial value\u00a01.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/388/0*7VbDByOQ6YxVh96u\"><figcaption><em>New shared value initialization.</em></figcaption></figure><p>Now\u2019s the time to use it. Let\u2019s use the useAnimatedStyle. Inside we can see three props changed based on openAnimation shared value: scale, perspective, and\u00a0rotateY.</p>\n<p>The only necessary change is rotateY moved by 180 degrees but scale and perspective are making the animation so much prettier! You can try to tweak all those values to see how it changes the\u00a0look!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/652/0*kSjrseS07GqHTg8A\"><figcaption><em>Style logic controlling our card\u2019s flip animation.</em></figcaption></figure><p>Movement shared values like x and y are controlled by gesture handler. This time we would rather flip the card by using a trigger inside the code. That\u2019s why I added a new button that controls the openAnimation shared value. It should be animated from initial 1 to 2 and back again. This time around we can use a new function: instead of withSpring\u200a\u2014\u200athat we are already familiar with\u200a\u2014\u200awe can use new withTiming.</p>\n<p>It works almost the same as withSpring but this time around it\u2019s not calculated based on physics values, but it\u2019s based on some predefined bezier curve the animation will follow. All animation adjustments can be set in the config object, but in my case, I only adjusted the duration of the animation to make it a little longer than the default\u00a0value.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/675/0*SjjRuUsdf7nSnN__\"><figcaption><em>Pressing this button will flip the\u00a0card.</em></figcaption></figure><h3>Creating card\u2019s front and back\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-4\">iteration-4</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/381/0*9S4omDaULckBtewE\"><figcaption><em>Result of iteration-4 code.</em></figcaption></figure><p>This step\u2019s gonna be\u00a0easy!</p>\n<p>This time around the only thing we add is just some graphics for the card front and reverse. For that reason, in our render method, we can find new <em>CardPerson.js</em> and <em>CardReverse.js</em>.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*6Ur0VOrTY8IC4Wk7\"></figure><p>But\u2026we can\u2019t just simply add them. We also need to write a logic that will determine when to show the card and which side of the card should be presented. Since we know the card flip animation is based on openAnimation shared value that travels between values 1 and 2, we can safely assume we should stop rendering the reverse just in the middle when the value exceeds\u00a01.5.</p>\n<p>For that reason, we can add a new opacity prop to previously created animatedFront style, that will switch whenever the value exceeds 1.5\u00a0.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/636/0*p-h9Rlim5HyBQsLD\"></figure><p>And very similar animatedBack style but with reversed\u00a0values:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/649/0*99NB8OVb2WPdOboO\"></figure><h3>Animated shadows\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-5\">iteration-5</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/412/0*nVV2yTUk3MfHUu6k\"><figcaption><em>Result of iteration-5 code.</em></figcaption></figure><p>Adding shadows will bring some additional depth to our animation. It\u2019s a simple, yet effective trick to add some depth to any 3D animation. I\u2019m totally aware this trick won\u2019t work in all cases, but adding it on a simple 2D plane can be a breeze using the new Reanimated.</p>\n<p>First things first, we need to update our render. To keep the single responsibility rule introduced earlier I decided to create two new Animated.View\u200a\u2014\u200aone for each side of the\u00a0card.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*hV8jUqEccucHwkVU\"><figcaption><em>New shadow components added to our render\u00a0method.</em></figcaption></figure><p>The trick here is to use position: absolute combined with relatively high zIndex and size spread over the whole component so the shadow would cover the component but won\u2019t infringe the internal flow while covering\u00a0it.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/349/0*HaT3uh2wQX2J_kc3\"><figcaption><em>Shadow basic\u00a0styles.</em></figcaption></figure><p>Finally, we can connect it with our openAnimation shared value. If you have a really sharp eye you can spot I used Extrapolate.CLAMP instead Extrapolate.EXTEND in the interpolation function. That\u2019s because I didn\u2019t want the opacity value to wander around out of control. CLAMP will keep the last given value and won\u2019t extrapolate it further. It makes sure that the opacity will never go below 0 or above 1. If that ever happened, it would have a disastrous effect: the react-native component would be confused, and every value not in range between 0 and 1 would return just 1. That means strange visual glitches out of our\u00a0control.</p>\n<p>NOT EPIC.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/550/0*cRKcqgWmTdqLNkv2\"><figcaption><em>Shadow animated\u00a0styles.</em></figcaption></figure><h3>We\u2019ve done a\u00a0lot!</h3>\n<p>We are almost done with work around our card. It looks amazing isn\u2019t it? During our journey we used a lot of different tools around reanimated 2 and I hope you are getting familiar with\u00a0it!</p>\n<p>Can you see the schema\u00a0already?</p>\n<p>First, we create shared we can\u00a0use:</p>\n<pre>const mySharedValue = useSharedValue(0);</pre>\n<p>Then we start creating Animated.View with useAnimatedStyle object\u00a0inside:</p>\n<pre>&lt;Animated.View style={animatedStyle} /&gt;</pre>\n<p>Created useAnimatedStyle always use some sharedValue to calculate new\u00a0style:</p>\n<pre>const animatedFront = useAnimatedStyle(() =&gt; {<br>  return {<br>    height: mySharedValue.value,<br>  };<br>});</pre>\n<p>And finally, we use some reanimated mechanism like withTiming or withSpring to animate\u00a0it:</p>\n<pre>mySharedValue.value = withTiming(100);</pre>\n<p>You are a quick learner!\u00a0\ud83d\udc4f</p>\n<p>Next time we will make the application alive by creating basic game logic to control the whole experience, start menu and loading animation! It\u2019s also gonna be the last part of our journey so stay tuned and see you\u00a0soon!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=66c127a210e9\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/building-reigns-how-to-strengthen-reign-over-mobile-game-development-using-reanimated-2-66c127a210e9\">Building Reigns: How to strengthen reign over mobile game development using Reanimated 2.</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "react-native",
                "mobile-games",
                "app-development",
                "reanimated"
            ]
        },
        {
            "title": "Building Reigns: How to reign over mobile game development using Reanimated 2.",
            "pubDate": "2021-05-18 10:21:19",
            "link": "https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/9402622c1fe5",
            "author": "Wojciech Stanisz",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*QKqG25zeY9_qlzUolU6p4Q.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QKqG25zeY9_qlzUolU6p4Q.png\"></figure><p>This week we start a three-part series of articles focused on building a clone of <a href=\"https://apps.apple.com/us/app/reigns/id1114127463\">Reigns</a> in React Native using <a href=\"https://github.com/software-mansion/react-native-reanimated\">Reanimated 2</a> and <a href=\"https://github.com/software-mansion/react-native-gesture-handler\">Gesture Handler.</a> The tutorial is backed by a Github repo with the full source code for the\u00a0project.</p>\n<p>Now, in this part, I lead you through the basics of Reanimated 2 new API and I will show you how it can be used to build nice gesture-based interactions for our\u00a0game.</p>\n<h3>Why I even started building\u00a0Reigns?</h3>\n<p>Every time I explore a new library I start by digging into examples to see what\u2019s even possible, if the library is actually working and if I can understand the code right away. Then I explore further\u200a\u2014\u200aI try to change some code and see if I can work with\u00a0it.</p>\n<p>I had the same approach to Reanimated 2. Or at least\u200a\u2014\u200aI wanted to approach it the same way I always do, but at the time (which was 9 months ago) there were nearly no examples. When I started to use the library for the first time it was an early alpha version so there was merely a playground with one slider and some examples in the docs about specific functions.</p>\n<p>Nothing fancy.</p>\n<p>Nothing to really play around\u00a0with.</p>\n<p>If you learn the same way as I do\u200a\u2014\u200aexploring and tweaking some existing examples\u200a\u2014\u200alet me tell you, Reanimated 2 was a real challenge. That\u2019s why I decided to create my own example for everybody to try Reanimated 2\u00a0out!</p>\n<p>Disclaimer: in this tutorial, I\u2019m using icons created by<a href=\"https://www.freepik.com/\"> FreePik</a> downloaded from<a href=\"https://www.flaticon.com/\"> FlatIcon</a> library. This is one amazing set of icons I highly encourage you to take a look\u00a0at.</p>\n<h3>What we\u2019re going to work\u00a0on?</h3>\n<p>As an example project, I wanted to take something that would combine a lot of different techniques and solutions at once. While looking for inspiration I was going through my Switch games library. And there it\u00a0was.</p>\n<p><a href=\"https://store.steampowered.com/app/474750/Reigns/\">Reigns</a>.</p>\n<p>Long story short\u200a\u2014\u200athis is a phenomenal game and you just have to try it out yourself! The overall game rules\u00a0are:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*-1Qs9swErILYTEj-deEWgw.gif\"><figcaption><em>Example in its final\u00a0state.</em></figcaption></figure><ul>\n<li>players have to answer continuous questions selecting from two available options;</li>\n<li>each question is presented in a form of an animated card that players can swipe left or right to select an\u00a0answer;</li>\n<li>each answer has consequences. Some decisions can appeal to one group while being oppressive to others. The player has to rule in a way that no group is privileged or discriminated against in the long\u00a0term.</li>\n</ul>\n<p>That\u2019s all you have to know to follow this tutorial.</p>\n<p><em>Let\u2019s go!</em></p>\n<h3>Before we start\u200a\u2014\u200aa few words on technicalities.</h3>\n<p>To take full advantage of this tutorial you need to know the basics of react-native. I assume you have a basic understanding of how react-native works and how to write simple components.</p>\n<h3>First step</h3>\n<p>I created a<a href=\"https://github.com/wojtus7/reanimated-story-cards\"> GitHub repo</a> I highly recommend cloning and building on your own machine. It contains step-by-step changes sorted into separate branches called <em>iterations </em>with the following numbers from 0 to 9. It helped me to focus only on important changes in this text while providing a wider, more interesting example, without forcing you to dig through a big codebase.</p>\n<p>Each chapter of this article is named: <em>name (iteration-X),</em> so you can follow the branches accordingly.</p>\n<p>The following project is based solely on<a href=\"https://github.com/software-mansion-labs/reanimated-2-playground\"> Reanimated 2 Playground</a>. If you have any trouble building it I recommend you check out the<a href=\"https://github.com/software-mansion-labs/reanimated-2-playground/issues\"> issues</a>\u00a0first.</p>\n<h3>Overview\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-0\">iteration-0</a>\n</h3>\n<p>Before we start to dig deeper into the Reanimated library I wanted to talk a little about the initial state of the project. You can see a lot of files but for now, we are interested only in 3 of\u00a0them:</p>\n<ul>\n<li><em>useGeneratedCards.js</em></li>\n<li><em>Screen.js</em></li>\n<li><em>Card.js</em></li>\n</ul>\n<p><em>useGeneratedCards</em> is our small database, containing separate cards that will be shown in the game.\u00a0Example:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/696/0*_KK-JyuCnewiO_uO\"><figcaption><em>Example card from useGeneratedCards.js.</em></figcaption></figure><p>question, leftText and rightText are just strings to be shown during each turn. onLeft and onRight are used in answer handlers: they inform us what are the consequences for each answer. Three possible personas to amuse are Woman, Knight, and Joker. Last things are image and background that determine the final looks of the\u00a0card.</p>\n<p>Next, we have <em>Screen.js</em>. This is the main screen of the application. We will hold all necessary components there. For now, we can see that it returns a simple wrapper with a single Card in\u00a0it.</p>\n<p>We don\u2019t have any logic yet so for the time being current card is hardcoded.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/564/0*eyrOKHYiFVJW2EKL\"><figcaption><em>The initial state of Screen.js.</em></figcaption></figure><p>The <em>Card.js</em> itself is a tiny component with a small render that contains a static card preview. I kept Styles simple for\u00a0clarity.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/510/0*11CtBgwGXjO0sQN-\"><figcaption><em>Card.js contains only a simple View for the time\u00a0being.</em></figcaption></figure><p>If you successfully built the project the screen should look like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*E2O_hy7oqZNDw3-X\"><figcaption><em>Just a square.\u00a0\u2b1c\ufe0f</em></figcaption></figure><p>Cool!</p>\n<p>We are ready to put some life into that static card of\u00a0ours!</p>\n<h3>Gesture handler + Reanimated 2\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-1\">iteration-1</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*U38rEtl6vxomqi9w\"><figcaption><em>Result of iteration-1 code.</em></figcaption></figure><p>Gesture Handler and Reanimated libraries are very closely related. More than often we need to animate some movement initiated by a finger\u00a0gesture.</p>\n<p>That\u2019s also the case here. We want to smoothly follow the finger swiping left and right, while dynamically showing the card content. For cases like this, we can use PanGestureHandler and connect it with a bright new useAnimatedGestureHandler hook introduced in Reanimated 2.</p>\n<p>But before we can focus on the gesture handler itself we need to take care of a few\u00a0things.</p>\n<p>First, we need to make sure that we can animate our Card. For that, we simply replace View with powerful Animated.View. It works the same as standard View for the most part but now we can use<em> shared values</em> to set the styles\u00a0\ud83c\udf89.</p>\n<p>But wait\u2026 What are those <em>shared values</em> in the first\u00a0place?</p>\n<p>Let me\u00a0explain!</p>\n<p>Reanimated can\u2019t use any JS variables to animate objects. We need to create specific values to be used in animations. Those are called <em>shared values</em> since they are shared between JS thread and UI thread of the react-native application.<a href=\"https://dev.to/goodpic/understanding-react-native-architecture-22hh\"> (More about UI and JS threads\u00a0here)</a>.</p>\n<p>We want to be able to move our card in any direction so we will need two shared values that will move our component in both the x and y axes. The default values for those variables should be 0 since we don\u2019t want any translation applied from the\u00a0start.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/322/0*NcldAwgZsUjUFt52\"><figcaption><em>Shared values initialization.</em></figcaption></figure><p>Now we need to edit our render function wrapping brand new Animated.View with PanGestureHandler. This component will track all pan gestures such as\u00a0swiping.</p>\n<p>The final render looks more or less like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/657/0*UNZGmbGqZDCewpTN\"><figcaption><em>Card with PanGestureHandler and Animated.View.</em></figcaption></figure><p>But wait there\u2019s\u00a0more!</p>\n<p>We have two new elements introduced here that I haven\u2019t mentioned before: gestureHandler and animatedMovableCard.</p>\n<p>Let\u2019s start with the first one. gestureHandler is constructed with useAnimatedGestureHandler hook imported straight from the Reanimated library. This is a new simple and amazing way to transform your input into shared values. It also can have a separate block of code for every single event like: onStart\u00a0, onActive and onEnd. <br>EPIC!</p>\n<p>The simplest version of handler for our example would contain only onActive updating x and y based on the position of the finger, and reset the position when the finger is released using onEnd\u00a0handler.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/496/0*0mOZNkOc9xSrNcUx\"></figure><p>But it\u2019s not enough. We strive for perfection here!\u00a0Upgrade!</p>\n<p>First things first, we need to create onStart where we use ctx object and keep the initial position of the card there. ctx is an object we can use to store any variables between onStart\u00a0, onActive and onEnd without the need to create new shared value in the component. In our example, saving initial position for x and y value can be quite useful in preventing some strange visual glitches. For example, when the user catches the card in the middle of the move and the card is off-center (eg. when the card is released without choosing any side and should animate back to the original position) we want to add this initial translation to the event translation itself.</p>\n<p>That\u2019s exactly what we\u2019re going to do in onActive\u00a0: add initial ctx values to captured event.translation.</p>\n<p>Finally, we want our card to animate smoothly to the starting position. There are a couple of ways to animate some value to a given value. First, I\u2019m going to introduce you to the mechanism that can smoothly animate any variable to a given value using physics: withSpring. Additionally, to make things spicier we can create our own config we want to use in a given spring animation. Pretty!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/532/0*xAaljf59OzscI5cr\"><figcaption><em>The final version of our gesture\u00a0handler.</em></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/365/0*jNXvq4_QLbgfC53C\"><figcaption><em>Custom spring config used in `withSpring` above.</em></figcaption></figure><p>Now that we have our gesture handler ready, it can start updating the shared values as we pan the finger. However, this won\u2019t result in any movements of the grey box. The only thing left is to map the values to actual Animated.View styles such that to tell how the UI should update when the gesture is happening.</p>\n<p>Now, let\u2019s look at the second element I previously mentioned -animatedMovableCard. We can see that it contains a useAnimatedStyle hook. Inside it, we can create any function that can use shared values and return some style object. In our case, we just use x as translateX and y as translateY\u00a0. That would be enough to make our card move, but to make it prettier we can add some rotationZ such that it rotates a little as it goes away from the\u00a0center.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/521/0*bA_3xgfTeBsqP55o\"><figcaption><em>Animated.View\u2019s animated\u00a0style.</em></figcaption></figure><p>To calculate rotation we can use brand new reimplemented Reanimated 2\u2019s interpolate function. The new one expects 4 arguments: shared value, input table, output value, kind of extrapolation.</p>\n<p>In the above example, we want to make interpolation based on x that will be mapped in that way so x.value = 50 would return 0.05 and x.value = -25 would return -0.025\u00a0, and thanks to the use of Extrapolate.Extend all values beyond the given range will be extrapolated correctly in a given manner eg. x.value = 750 will be\u00a00.75.</p>\n<h3>Just a first\u00a0step</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*9g7MIGJW2WB2HLR2\"><figcaption><em>Part 1 final\u00a0effect.</em></figcaption></figure><p>Every journey begins with a single step. In our case, it was a rather giant\u00a0leap.</p>\n<p>During this short time, we covered a lot about Reanimated 2. We got familiar with new shared values, we used new useAnimatedGestureHandler and totally new useAnimatedStyle.</p>\n<p>That\u2019s a pretty solid foundation, but it means nothing without exercise! Go into the example and have fun with it! Change things, tweak, break and fix all you want, and stay tuned for the next part where we\u2019re gonna add more awesome things like flip animation, shadows, loading animation, and much\u00a0more!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9402622c1fe5\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">Building Reigns: How to reign over mobile game development using Reanimated 2.</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*QKqG25zeY9_qlzUolU6p4Q.png\"></figure><p>This week we start a three-part series of articles focused on building a clone of <a href=\"https://apps.apple.com/us/app/reigns/id1114127463\">Reigns</a> in React Native using <a href=\"https://github.com/software-mansion/react-native-reanimated\">Reanimated 2</a> and <a href=\"https://github.com/software-mansion/react-native-gesture-handler\">Gesture Handler.</a> The tutorial is backed by a Github repo with the full source code for the\u00a0project.</p>\n<p>Now, in this part, I lead you through the basics of Reanimated 2 new API and I will show you how it can be used to build nice gesture-based interactions for our\u00a0game.</p>\n<h3>Why I even started building\u00a0Reigns?</h3>\n<p>Every time I explore a new library I start by digging into examples to see what\u2019s even possible, if the library is actually working and if I can understand the code right away. Then I explore further\u200a\u2014\u200aI try to change some code and see if I can work with\u00a0it.</p>\n<p>I had the same approach to Reanimated 2. Or at least\u200a\u2014\u200aI wanted to approach it the same way I always do, but at the time (which was 9 months ago) there were nearly no examples. When I started to use the library for the first time it was an early alpha version so there was merely a playground with one slider and some examples in the docs about specific functions.</p>\n<p>Nothing fancy.</p>\n<p>Nothing to really play around\u00a0with.</p>\n<p>If you learn the same way as I do\u200a\u2014\u200aexploring and tweaking some existing examples\u200a\u2014\u200alet me tell you, Reanimated 2 was a real challenge. That\u2019s why I decided to create my own example for everybody to try Reanimated 2\u00a0out!</p>\n<p>Disclaimer: in this tutorial, I\u2019m using icons created by<a href=\"https://www.freepik.com/\"> FreePik</a> downloaded from<a href=\"https://www.flaticon.com/\"> FlatIcon</a> library. This is one amazing set of icons I highly encourage you to take a look\u00a0at.</p>\n<h3>What we\u2019re going to work\u00a0on?</h3>\n<p>As an example project, I wanted to take something that would combine a lot of different techniques and solutions at once. While looking for inspiration I was going through my Switch games library. And there it\u00a0was.</p>\n<p><a href=\"https://store.steampowered.com/app/474750/Reigns/\">Reigns</a>.</p>\n<p>Long story short\u200a\u2014\u200athis is a phenomenal game and you just have to try it out yourself! The overall game rules\u00a0are:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/1*-1Qs9swErILYTEj-deEWgw.gif\"><figcaption><em>Example in its final\u00a0state.</em></figcaption></figure><ul>\n<li>players have to answer continuous questions selecting from two available options;</li>\n<li>each question is presented in a form of an animated card that players can swipe left or right to select an\u00a0answer;</li>\n<li>each answer has consequences. Some decisions can appeal to one group while being oppressive to others. The player has to rule in a way that no group is privileged or discriminated against in the long\u00a0term.</li>\n</ul>\n<p>That\u2019s all you have to know to follow this tutorial.</p>\n<p><em>Let\u2019s go!</em></p>\n<h3>Before we start\u200a\u2014\u200aa few words on technicalities.</h3>\n<p>To take full advantage of this tutorial you need to know the basics of react-native. I assume you have a basic understanding of how react-native works and how to write simple components.</p>\n<h3>First step</h3>\n<p>I created a<a href=\"https://github.com/wojtus7/reanimated-story-cards\"> GitHub repo</a> I highly recommend cloning and building on your own machine. It contains step-by-step changes sorted into separate branches called <em>iterations </em>with the following numbers from 0 to 9. It helped me to focus only on important changes in this text while providing a wider, more interesting example, without forcing you to dig through a big codebase.</p>\n<p>Each chapter of this article is named: <em>name (iteration-X),</em> so you can follow the branches accordingly.</p>\n<p>The following project is based solely on<a href=\"https://github.com/software-mansion-labs/reanimated-2-playground\"> Reanimated 2 Playground</a>. If you have any trouble building it I recommend you check out the<a href=\"https://github.com/software-mansion-labs/reanimated-2-playground/issues\"> issues</a>\u00a0first.</p>\n<h3>Overview\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-0\">iteration-0</a>\n</h3>\n<p>Before we start to dig deeper into the Reanimated library I wanted to talk a little about the initial state of the project. You can see a lot of files but for now, we are interested only in 3 of\u00a0them:</p>\n<ul>\n<li><em>useGeneratedCards.js</em></li>\n<li><em>Screen.js</em></li>\n<li><em>Card.js</em></li>\n</ul>\n<p><em>useGeneratedCards</em> is our small database, containing separate cards that will be shown in the game.\u00a0Example:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/696/0*_KK-JyuCnewiO_uO\"><figcaption><em>Example card from useGeneratedCards.js.</em></figcaption></figure><p>question, leftText and rightText are just strings to be shown during each turn. onLeft and onRight are used in answer handlers: they inform us what are the consequences for each answer. Three possible personas to amuse are Woman, Knight, and Joker. Last things are image and background that determine the final looks of the\u00a0card.</p>\n<p>Next, we have <em>Screen.js</em>. This is the main screen of the application. We will hold all necessary components there. For now, we can see that it returns a simple wrapper with a single Card in\u00a0it.</p>\n<p>We don\u2019t have any logic yet so for the time being current card is hardcoded.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/564/0*eyrOKHYiFVJW2EKL\"><figcaption><em>The initial state of Screen.js.</em></figcaption></figure><p>The <em>Card.js</em> itself is a tiny component with a small render that contains a static card preview. I kept Styles simple for\u00a0clarity.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/510/0*11CtBgwGXjO0sQN-\"><figcaption><em>Card.js contains only a simple View for the time\u00a0being.</em></figcaption></figure><p>If you successfully built the project the screen should look like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*E2O_hy7oqZNDw3-X\"><figcaption><em>Just a square.\u00a0\u2b1c\ufe0f</em></figcaption></figure><p>Cool!</p>\n<p>We are ready to put some life into that static card of\u00a0ours!</p>\n<h3>Gesture handler + Reanimated 2\u200a\u2014\u200a<a href=\"https://github.com/wojtus7/reanimated-story-cards/tree/iteration-1\">iteration-1</a>\n</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*U38rEtl6vxomqi9w\"><figcaption><em>Result of iteration-1 code.</em></figcaption></figure><p>Gesture Handler and Reanimated libraries are very closely related. More than often we need to animate some movement initiated by a finger\u00a0gesture.</p>\n<p>That\u2019s also the case here. We want to smoothly follow the finger swiping left and right, while dynamically showing the card content. For cases like this, we can use PanGestureHandler and connect it with a bright new useAnimatedGestureHandler hook introduced in Reanimated 2.</p>\n<p>But before we can focus on the gesture handler itself we need to take care of a few\u00a0things.</p>\n<p>First, we need to make sure that we can animate our Card. For that, we simply replace View with powerful Animated.View. It works the same as standard View for the most part but now we can use<em> shared values</em> to set the styles\u00a0\ud83c\udf89.</p>\n<p>But wait\u2026 What are those <em>shared values</em> in the first\u00a0place?</p>\n<p>Let me\u00a0explain!</p>\n<p>Reanimated can\u2019t use any JS variables to animate objects. We need to create specific values to be used in animations. Those are called <em>shared values</em> since they are shared between JS thread and UI thread of the react-native application.<a href=\"https://dev.to/goodpic/understanding-react-native-architecture-22hh\"> (More about UI and JS threads\u00a0here)</a>.</p>\n<p>We want to be able to move our card in any direction so we will need two shared values that will move our component in both the x and y axes. The default values for those variables should be 0 since we don\u2019t want any translation applied from the\u00a0start.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/322/0*NcldAwgZsUjUFt52\"><figcaption><em>Shared values initialization.</em></figcaption></figure><p>Now we need to edit our render function wrapping brand new Animated.View with PanGestureHandler. This component will track all pan gestures such as\u00a0swiping.</p>\n<p>The final render looks more or less like\u00a0this:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/657/0*UNZGmbGqZDCewpTN\"><figcaption><em>Card with PanGestureHandler and Animated.View.</em></figcaption></figure><p>But wait there\u2019s\u00a0more!</p>\n<p>We have two new elements introduced here that I haven\u2019t mentioned before: gestureHandler and animatedMovableCard.</p>\n<p>Let\u2019s start with the first one. gestureHandler is constructed with useAnimatedGestureHandler hook imported straight from the Reanimated library. This is a new simple and amazing way to transform your input into shared values. It also can have a separate block of code for every single event like: onStart\u00a0, onActive and onEnd. <br>EPIC!</p>\n<p>The simplest version of handler for our example would contain only onActive updating x and y based on the position of the finger, and reset the position when the finger is released using onEnd\u00a0handler.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/496/0*0mOZNkOc9xSrNcUx\"></figure><p>But it\u2019s not enough. We strive for perfection here!\u00a0Upgrade!</p>\n<p>First things first, we need to create onStart where we use ctx object and keep the initial position of the card there. ctx is an object we can use to store any variables between onStart\u00a0, onActive and onEnd without the need to create new shared value in the component. In our example, saving initial position for x and y value can be quite useful in preventing some strange visual glitches. For example, when the user catches the card in the middle of the move and the card is off-center (eg. when the card is released without choosing any side and should animate back to the original position) we want to add this initial translation to the event translation itself.</p>\n<p>That\u2019s exactly what we\u2019re going to do in onActive\u00a0: add initial ctx values to captured event.translation.</p>\n<p>Finally, we want our card to animate smoothly to the starting position. There are a couple of ways to animate some value to a given value. First, I\u2019m going to introduce you to the mechanism that can smoothly animate any variable to a given value using physics: withSpring. Additionally, to make things spicier we can create our own config we want to use in a given spring animation. Pretty!</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/532/0*xAaljf59OzscI5cr\"><figcaption><em>The final version of our gesture\u00a0handler.</em></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/365/0*jNXvq4_QLbgfC53C\"><figcaption><em>Custom spring config used in `withSpring` above.</em></figcaption></figure><p>Now that we have our gesture handler ready, it can start updating the shared values as we pan the finger. However, this won\u2019t result in any movements of the grey box. The only thing left is to map the values to actual Animated.View styles such that to tell how the UI should update when the gesture is happening.</p>\n<p>Now, let\u2019s look at the second element I previously mentioned -animatedMovableCard. We can see that it contains a useAnimatedStyle hook. Inside it, we can create any function that can use shared values and return some style object. In our case, we just use x as translateX and y as translateY\u00a0. That would be enough to make our card move, but to make it prettier we can add some rotationZ such that it rotates a little as it goes away from the\u00a0center.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/521/0*bA_3xgfTeBsqP55o\"><figcaption><em>Animated.View\u2019s animated\u00a0style.</em></figcaption></figure><p>To calculate rotation we can use brand new reimplemented Reanimated 2\u2019s interpolate function. The new one expects 4 arguments: shared value, input table, output value, kind of extrapolation.</p>\n<p>In the above example, we want to make interpolation based on x that will be mapped in that way so x.value = 50 would return 0.05 and x.value = -25 would return -0.025\u00a0, and thanks to the use of Extrapolate.Extend all values beyond the given range will be extrapolated correctly in a given manner eg. x.value = 750 will be\u00a00.75.</p>\n<h3>Just a first\u00a0step</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/400/0*9g7MIGJW2WB2HLR2\"><figcaption><em>Part 1 final\u00a0effect.</em></figcaption></figure><p>Every journey begins with a single step. In our case, it was a rather giant\u00a0leap.</p>\n<p>During this short time, we covered a lot about Reanimated 2. We got familiar with new shared values, we used new useAnimatedGestureHandler and totally new useAnimatedStyle.</p>\n<p>That\u2019s a pretty solid foundation, but it means nothing without exercise! Go into the example and have fun with it! Change things, tweak, break and fix all you want, and stay tuned for the next part where we\u2019re gonna add more awesome things like flip animation, shadows, loading animation, and much\u00a0more!</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9402622c1fe5\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/reanimated-2-the-game-9402622c1fe5\">Building Reigns: How to reign over mobile game development using Reanimated 2.</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "reanimated",
                "react-native",
                "animation",
                "mobile-games"
            ]
        },
        {
            "title": "iCalendar, CalDAV &amp; Elixir",
            "pubDate": "2021-03-29 11:20:25",
            "link": "https://blog.swmansion.com/icalendar-caldav-elixir-13be601572eb?source=rss----e003bf129483---4",
            "guid": "https://medium.com/p/13be601572eb",
            "author": "Tomasz Zawadzki",
            "thumbnail": "https://cdn-images-1.medium.com/max/1024/1*1RR1qz4GpLjnHKDOzXJikg.png",
            "description": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1RR1qz4GpLjnHKDOzXJikg.png\"></figure><p>In this blog post I will share some insights on storing and processing events in online calendars. Even though the topic seems to be well standardized, there are still some caveats that one may easily overlook. I hope this article provides some useful tips for developers who need to deal with datetimes, events and calendars.</p>\n<h3>A quick note on datetimes and time\u00a0zones</h3>\n<p>Datetimes without time zone can be ambiguous and dependent on the configuration as they clearly miss the context. In the vast majority of cases, it is recommended to process and store datetimes with time zones, because they always represent a specific and unique point in\u00a0time.</p>\n<p>While some programming languages offer a limited set of tools to deal with dates and times out of the box and shift the responsibility towards third-party libraries, Elixir has great built-in support for dates, times, and time zones. It is even possible to implement a custom calendar by implementing the <a href=\"https://hexdocs.pm/elixir/Calendar.html\">Calendar behavior</a>.</p>\n<p>There are many ways to represent and store datetimes in Elixir, for\u00a0example:</p>\n<ul>\n<li>as <a href=\"https://en.wikipedia.org/wiki/Unix_time\">Unix timestamp</a>, e.g. 1617280200</li>\n<li>the <a href=\"https://erlang.org/doc/man/calendar.html#data-types\">Erlang-style</a>, e.g. {{2021, 4, 1}, {12, 30,\u00a00}}</li>\n<li>as <a href=\"https://hexdocs.pm/elixir/NaiveDateTime.html\">NaiveDateTime</a>, e.g. ~N[2021-04-01 12:30:00]</li>\n<li>as <a href=\"https://hexdocs.pm/elixir/DateTime.html\">DateTime</a>, e.g. #DateTime&lt;2021-04-01 14:30:00+02:00 CEST Europe/Warsaw&gt; or ~U[2021-04-01 12:30:00Z]</li>\n</ul>\n<p>The ~N sigil represents NaiveDateTime (without time zone) and the ~U sigil represents a DateTime in UTC timezone also known as \u201cZ time\u201d or \u201cZulu Time\u201d, hence the \u201cZ\u201d at the\u00a0end.</p>\n<blockquote>Fun fact: The \u201cEtc\u201d in Etc/UTC actually stands for \u201cet cetera\u201d. That\u2019s because the names in the <a href=\"https://en.wikipedia.org/wiki/Tz_database\">tz database</a> follow the convention Area/Location, for example Europe/Warsaw or America/New_York.</blockquote>\n<h3>iCalendar</h3>\n<p>When it comes to representing and exchanging the calendar events, the clear winner is the iCalendar format defined in <a href=\"https://tools.ietf.org/html/rfc2445\">RFC 2445</a> from November 1998 and revised by <a href=\"https://tools.ietf.org/html/rfc5545\">RFC 5545</a> in September 2009. Although the dates from past decades may suggest that the standard is pretty outdated, it is still widely used in multiple applications due to interoperability reasons. It is worth mentioning that the iCalendar specification also defines how to represent to-dos (tasks), journal entries, and free/busy information.</p>\n<p>The example iCalendar file looks like\u00a0this:</p>\n<pre>BEGIN:VCALENDAR<br>VERSION:2.0<br>PRODID:-//hacksw/handcal//NONSGML v1.0//EN<br>BEGIN:VEVENT<br>UID:19970610T172345Z-AF23B2@example.com<br>DTSTAMP:19970610T172345Z<br>DTSTART:19970714T170000Z<br>DTEND:19970715T040000Z<br>SUMMARY:Bastille Day Party<br>END:VEVENT<br>END:VCALENDAR</pre>\n<p>When defining the meeting start and end time, you can specify the time zone identifier as\u00a0well:</p>\n<pre>DTSTART;TZID=Europe/Warsaw:20210301T114500<br>DTEND;TZID=Europe/Warsaw:20210301T120000</pre>\n<blockquote>Note: This is especially important if the meeting is scheduled with reference to a specific timezone, e.g. daily at 11:45 in Europe/Warsaw. If you represent the meeting start time with DTSTART:20210301T104500Z instead, the meeting will begin either at 11:45 or 12:45, winter or summer time, respectively.</blockquote>\n<p>It is also possible to define full-day events, but keep in mind that the DTEND property is exclusive, so the full-day meeting on April 1st, 2021 should actually end on April 2nd,\u00a02021:</p>\n<pre>DTSTART;VALUE=DATE:20210401<br>DTEND;VALUE=DATE:20210402</pre>\n<p>Multiple event details can be provided, including start time and duration, summary, category, description, location, attachments, organizer, and the attendees list. The event can also have multiple alarms (VALARM) which trigger on an exact date or a specified interval before the event\u00a0starts.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TrC7oU0SVObfobJgF_6FNQ.png\"><figcaption>It is possible to define multiple alarms with a wide range of trigger intervals for a single\u00a0event.</figcaption></figure><p>While most of the properties are optional, UID (unique identifier), DTSTAMP (usually a modification date), and DTSTART (start time) are quite essential. You may also use non-standard properties starting with X- for storing custom event attributes that are specific to your application.</p>\n<p>It is a common practice to attach an iCalendar file (usually named invite.ics or event.ics) to the email. This allows Gmail (and many other clients) to intercept the attachment and interpret the message as an invitation, allowing you to add the event to your calendar:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*hhVt9OpQpp_JHo1gDpanVQ.png\"><figcaption>Gmail will automatically fetch the event details from the attached iCalendar file.</figcaption></figure><p>Many calendar servers also provide a link, usually containing a secret token, pointing to the iCalendar feed, which can be used to subscribe to the calendar in read-only mode.</p>\n<h3>The mighty\u00a0RRULE</h3>\n<p>The true power of the iCalendar format is that it also allows us to represent recurring events. This is especially helpful if you want to add a daily or weekly appointment to your calendar. Recurring events can take place a specific number of times, repeat up to a specified date, or never end at\u00a0all.</p>\n<p>The DTSTART and DTEND or DURATION properties specify the first occurrence of the event and the RRULE parameter specifies the recursion scheme, for example, RRULE:FREQ=DAILY;COUNT=10 which means \u201c10 consecutive days\u201d. It is also possible to specify the exact dates when the meeting takes place using the RDATE property or remove unwanted occurrences from the recursion set using the EXDATE property (EXRULE has been deprecated). Make sure to check out this great <a href=\"https://jakubroztocil.github.io/rrule/\">rrule.js\u00a0demo</a>.</p>\n<p>A recurring event is stored as a single resource and all its instances share the same summary, description, etc. When you edit the event, the calendar client will usually ask you whether to edit only the single occurrence or all event instances.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*01Hyxv5CsglZpMN6inTMlw.png\"><figcaption>When editing or deleting a recurring event, Google Calendar will ask you which instances should be affected.</figcaption></figure><h3>CalDAV</h3>\n<p>In order to access the calendar from multiple devices, events can be stored on a remote calendar server. CalDAV (<a href=\"https://tools.ietf.org/html/rfc4791\">RFC 4791</a>, March 2008) is a protocol specification that defines how clients (for example Thunderbird or the calendar app on your phone) should interact with remote calendar servers (e.g. iCloud, Google Calendar, or your own instance).</p>\n<p>The idea behind CalDAV is to represent calendars as directories and events as iCalendar files. The protocol actually inherits from WebDAV, which is used for management and version control of files on the webserver. Each calendar user (or principal, according to CalDAV terminology) can have multiple calendars, which are identified by\u00a0URLs.</p>\n<p>An example CalDAV root URL:<br>http://example.com/path</p>\n<p>An example principal URL:<br>http://example.com/path<strong>/calendars/alice</strong></p>\n<p>An example calendar URL: <br>http://example.com/path<strong>/calendars/alice/work</strong></p>\n<p>An example event URL:<br>http://example.com/path<strong>/calendars/alice/work/meeting.ics</strong></p>\n<blockquote>Note: while many calendar clients use the same value (usually an <a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\">UUID</a> to ensure uniqueness) both for CalDAV event URL and iCalendar UID property, this is not an obligation. The\u00a0.ics suffix is optional, but recommended as\u00a0well.</blockquote>\n<p>CalDAV uses the HTTP protocol to send XML requests with custom HTTP methods (such as MKCALENDAR or REPORT) and receive XML responses containing iCalendar data. For authentication, usually HTTP Basic or Digest authentication is used; sometimes OAuth\u00a02.0.</p>\n<p>A fully-implemented CalDAV server must support managing calendars, events, alarms, to-dos (tasks), and journal entries as well as implement an ACL (access control list) mechanism to check the user\u2019s permissions to access or modify the resource. Additionally, there are multiple optional extensions to the CalDAV protocol, including <a href=\"https://tools.ietf.org/html/rfc6638\">RFC 6638</a> (Scheduling Extensions to CalDAV), which defines how to handle events with organizers and multiple attendees, allowing them to accept or decline invites. Many calendar servers also support the CardDAV protocol (<a href=\"https://www.ietf.org/rfc/rfc6352.txt\">RFC 6352</a>) protocol for accessing and sharing contact data (address books) using vCard format (*.vcf\u00a0files).</p>\n<blockquote>Note: when the organizer deletes an event, it will not be removed from attendees\u2019 calendars\u200a\u2014\u200ainstead the status will change to \u201ccancelled\u201d.</blockquote>\n<p>There are many open-source calendar servers available, including <a href=\"https://sabre.io/baikal/\">Ba\u00efkal</a>, <a href=\"https://www.davical.org/\">DAViCal</a>, <a href=\"https://radicale.org/3.0.html\">Radicale</a>, and <a href=\"https://www.calendarserver.org/\">Calendar and Contacts Server</a>. The key difference is the set of implemented features as well as RFC compliance and compatibility with different clients, i.e. the calendar app on your device, <a href=\"https://www.thunderbird.net/pl/\">Thunderbird</a>, etc. Some calendar servers may try to fix the improper data or even fill the missing properties, while others may simply reject the\u00a0request.</p>\n<ul>\n<li><a href=\"https://sabre.io/dav/standards-support/\">https://sabre.io/dav/standards-support/</a></li>\n<li><a href=\"https://github.com/jelmer/xandikos#implemented-standards\">https://github.com/jelmer/xandikos#implemented-standards</a></li>\n</ul>\n<p>While the CalDAV protocol seems to cover all reasonable requirements for a single user, it certainly offers no administrative functionalities to aggregate data from multiple existing calendars within a single response. Other calendar providers, for instance Google Calendar, may provide custom APIs for additional functionalities.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rGWbkXcqwF1MXwW01-5RMQ.png\"></figure><h3>Elixir CalDAV\u00a0Client</h3>\n<p>I was pretty surprised when I found out that there was no CalDAV client library for Elixir, so I wrote one. Currently, the library allows you\u00a0to:</p>\n<ul>\n<li>create, modify and delete the calendars,</li>\n<li>add, update and delete the events (with ETag and If-* headers support),</li>\n<li>get event from\u00a0URL,</li>\n<li>find an event by\u00a0UID,</li>\n<li>list all events happening or having an alarm within a specified time range<br>(with recurrence expansion enabled or disabled),</li>\n<li>retrieve events using custom XML requests,</li>\n<li>append custom HTTP headers via Tesla middlewares.</li>\n</ul>\n<p>Although the library implements only basic functionalities, it should be suitable for most of the applications. The library is <a href=\"https://hex.pm/packages/caldav_client\">published on Hex</a> and <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">available at Software Mansion Labs\u00a0GitHub</a>.</p>\n<p><a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">software-mansion-labs/elixir-caldav-client</a></p>\n<p>It is also worth mentioning that this library is only responsible for communication with the remote calendar server using CalDAV protocol and does not parse or serialize the iCalendar data. This approach allows the developers to use it in cooperation with any iCalendar parsing/serialization library (e.g. <a href=\"https://github.com/lpil/icalendar\">ICalendar</a> or <a href=\"https://github.com/kbrw/calibex\">Calibex</a>).</p>\n<p>To start with, you need to provide the server address as well as user credentials in the %CalDAVClient.Client struct:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*u0LBU4acJD9gN_bp__iRww.png\"></figure><p>You can generate the calendar URL using build_calendar_url/2 function:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zJl9_g-ibAmvrgU9kID2LA.png\"></figure><blockquote>Note: some calendar servers (including iCloud) use a custom scheme for calendar and event URLs. In such case, it is necessary to build the URL accordingly.</blockquote>\n<p>Then you may easily retrieve all events within a specified time range using get_events/4 function:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5U-NF3VAzU2l1QhAQKo6bA.png\"></figure><blockquote>Note: time ranges are start-inclusive and end-exclusive, so the results will not include any events starting at midnight on April 1st,\u00a02021.</blockquote>\n<p>You can also retrieve all instances of the events, i.e. with recurrence expansion enabled, by adding the expand: true option. Some calendar servers use naive implementations and some use more sophisticated algorithms, often natively implemented\u200a\u2014\u200athat\u2019s just an implementation detail, but certainly affects the overall performance and response\u00a0time.</p>\n<p>In order to create an event, just pass the event URL and iCalendar data to the CalDAVClient.Event.create/3 function. The following example uses the <a href=\"https://github.com/lpil/icalendar\">ICalendar</a> library to serialize an\u00a0event:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Rivz2ArVf01aNhfvVJjv_Q.png\"></figure><p>If you pass the etag option when modifying or deleting an event, the request will succeed only if the provided <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag\">ETag</a> matches the current version of the event, otherwise {:error,\u00a0:bad_etag} will be returned. This mechanism prevents simultaneous updates and ensures that the appropriate version of the event will be overwritten.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yhodno96Q9kYB7hkaRp5IQ.png\"></figure><p>Check out <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client/blob/master/README.md\">README</a> and the <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client/tree/master/examples\">examples</a> in the GitHub repository.</p>\n<h3>Demo</h3>\n<p>The following example demonstrates how to connect to a CalDAV server (for instance iCloud Calendar) in Elixir to create and list the events from your calendar:</p>\n<p><a href=\"https://github.com/software-mansion-labs/elixir-caldav-client-demo\">software-mansion-labs/elixir-caldav-client-demo</a></p>\n<pre>git clone https://github.com/software-mansion-labs/elixir-caldav-client-demo &amp;&amp; cd elixir-caldav-client-demo</pre>\n<p>Let\u2019s start by getting the dependencies:</p>\n<pre>mix deps.get</pre>\n<p>Then create a configuration file from the template:</p>\n<pre>cp .env.example .env</pre>\n<p>Next, generate an app-specific password and fill the credentials in the\u00a0.env file as described in <a href=\"https://frightanic.com/apple-mac/thunderbird-icloud-calendar-sync/\">this tutorial</a>. Finally, launch the Elixir console with environmental variables fetched from the\u00a0.env\u00a0file:</p>\n<pre>set -a &amp;&amp; source .env &amp;&amp; set +a &amp;&amp; iex -S mix</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WQlnbocVGQxQmJc9ixv3oQ.png\"><figcaption>Elixir CalDAV Client library allows you to manage and list the events from your iCloud calendar.</figcaption></figure><p>Additionally, notice that on March 28th, 2021 the timezone changes from CET (<em>Central European Time</em>) to CEST (<em>Central European Summer Time</em>)\u200a\u2014\u200athat\u2019s when DST (<em>Daylight Saving Time</em>) comes into play\u200a\u2014\u200aand it\u2019s all handled automatically by the calendar\u00a0server.</p>\n<h3>Main takeaways</h3>\n<ul>\n<li>Always use DateTime instead of NaiveDateTime unless you really know what you\u2019re\u00a0doing.</li>\n<li>The iCalendar format allows representing recurring events thanks to the RRULE property.</li>\n<li>If you ever need to connect to a remote calendar server from your Elixir application, we recommend you the <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">Elixir CalDAV Client</a>\u00a0library.</li>\n</ul>\n<h3>Elixir &amp; Open Source at Software\u00a0Mansion</h3>\n<p>Elixir has been an important focus area in Software Mansion for quite some time. We use this language in both commercial projects as well as to build and maintain one of our open source frameworks\u200a\u2014\u200aMembrane.</p>\n<p>Membrane is a multimedia processing framework that was created as an easy-to-use abstraction layer for assembling mostly server-side applications that have to consume, produce, or process multimedia streams. It\u2019s written in Elixir with the help of native code in\u00a0C.</p>\n<ul>\n<li><a href=\"https://www.membraneframework.org/\">Reliable &amp; scalable multimedia streaming</a></li>\n<li><a href=\"https://swmansion.com/community/open-source/\">Open Source - Software Mansion</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=13be601572eb\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/icalendar-caldav-elixir-13be601572eb\">iCalendar, CalDAV &amp; Elixir</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "content": "\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1RR1qz4GpLjnHKDOzXJikg.png\"></figure><p>In this blog post I will share some insights on storing and processing events in online calendars. Even though the topic seems to be well standardized, there are still some caveats that one may easily overlook. I hope this article provides some useful tips for developers who need to deal with datetimes, events and calendars.</p>\n<h3>A quick note on datetimes and time\u00a0zones</h3>\n<p>Datetimes without time zone can be ambiguous and dependent on the configuration as they clearly miss the context. In the vast majority of cases, it is recommended to process and store datetimes with time zones, because they always represent a specific and unique point in\u00a0time.</p>\n<p>While some programming languages offer a limited set of tools to deal with dates and times out of the box and shift the responsibility towards third-party libraries, Elixir has great built-in support for dates, times, and time zones. It is even possible to implement a custom calendar by implementing the <a href=\"https://hexdocs.pm/elixir/Calendar.html\">Calendar behavior</a>.</p>\n<p>There are many ways to represent and store datetimes in Elixir, for\u00a0example:</p>\n<ul>\n<li>as <a href=\"https://en.wikipedia.org/wiki/Unix_time\">Unix timestamp</a>, e.g. 1617280200</li>\n<li>the <a href=\"https://erlang.org/doc/man/calendar.html#data-types\">Erlang-style</a>, e.g. {{2021, 4, 1}, {12, 30,\u00a00}}</li>\n<li>as <a href=\"https://hexdocs.pm/elixir/NaiveDateTime.html\">NaiveDateTime</a>, e.g. ~N[2021-04-01 12:30:00]</li>\n<li>as <a href=\"https://hexdocs.pm/elixir/DateTime.html\">DateTime</a>, e.g. #DateTime&lt;2021-04-01 14:30:00+02:00 CEST Europe/Warsaw&gt; or ~U[2021-04-01 12:30:00Z]</li>\n</ul>\n<p>The ~N sigil represents NaiveDateTime (without time zone) and the ~U sigil represents a DateTime in UTC timezone also known as \u201cZ time\u201d or \u201cZulu Time\u201d, hence the \u201cZ\u201d at the\u00a0end.</p>\n<blockquote>Fun fact: The \u201cEtc\u201d in Etc/UTC actually stands for \u201cet cetera\u201d. That\u2019s because the names in the <a href=\"https://en.wikipedia.org/wiki/Tz_database\">tz database</a> follow the convention Area/Location, for example Europe/Warsaw or America/New_York.</blockquote>\n<h3>iCalendar</h3>\n<p>When it comes to representing and exchanging the calendar events, the clear winner is the iCalendar format defined in <a href=\"https://tools.ietf.org/html/rfc2445\">RFC 2445</a> from November 1998 and revised by <a href=\"https://tools.ietf.org/html/rfc5545\">RFC 5545</a> in September 2009. Although the dates from past decades may suggest that the standard is pretty outdated, it is still widely used in multiple applications due to interoperability reasons. It is worth mentioning that the iCalendar specification also defines how to represent to-dos (tasks), journal entries, and free/busy information.</p>\n<p>The example iCalendar file looks like\u00a0this:</p>\n<pre>BEGIN:VCALENDAR<br>VERSION:2.0<br>PRODID:-//hacksw/handcal//NONSGML v1.0//EN<br>BEGIN:VEVENT<br>UID:19970610T172345Z-AF23B2@example.com<br>DTSTAMP:19970610T172345Z<br>DTSTART:19970714T170000Z<br>DTEND:19970715T040000Z<br>SUMMARY:Bastille Day Party<br>END:VEVENT<br>END:VCALENDAR</pre>\n<p>When defining the meeting start and end time, you can specify the time zone identifier as\u00a0well:</p>\n<pre>DTSTART;TZID=Europe/Warsaw:20210301T114500<br>DTEND;TZID=Europe/Warsaw:20210301T120000</pre>\n<blockquote>Note: This is especially important if the meeting is scheduled with reference to a specific timezone, e.g. daily at 11:45 in Europe/Warsaw. If you represent the meeting start time with DTSTART:20210301T104500Z instead, the meeting will begin either at 11:45 or 12:45, winter or summer time, respectively.</blockquote>\n<p>It is also possible to define full-day events, but keep in mind that the DTEND property is exclusive, so the full-day meeting on April 1st, 2021 should actually end on April 2nd,\u00a02021:</p>\n<pre>DTSTART;VALUE=DATE:20210401<br>DTEND;VALUE=DATE:20210402</pre>\n<p>Multiple event details can be provided, including start time and duration, summary, category, description, location, attachments, organizer, and the attendees list. The event can also have multiple alarms (VALARM) which trigger on an exact date or a specified interval before the event\u00a0starts.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TrC7oU0SVObfobJgF_6FNQ.png\"><figcaption>It is possible to define multiple alarms with a wide range of trigger intervals for a single\u00a0event.</figcaption></figure><p>While most of the properties are optional, UID (unique identifier), DTSTAMP (usually a modification date), and DTSTART (start time) are quite essential. You may also use non-standard properties starting with X- for storing custom event attributes that are specific to your application.</p>\n<p>It is a common practice to attach an iCalendar file (usually named invite.ics or event.ics) to the email. This allows Gmail (and many other clients) to intercept the attachment and interpret the message as an invitation, allowing you to add the event to your calendar:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*hhVt9OpQpp_JHo1gDpanVQ.png\"><figcaption>Gmail will automatically fetch the event details from the attached iCalendar file.</figcaption></figure><p>Many calendar servers also provide a link, usually containing a secret token, pointing to the iCalendar feed, which can be used to subscribe to the calendar in read-only mode.</p>\n<h3>The mighty\u00a0RRULE</h3>\n<p>The true power of the iCalendar format is that it also allows us to represent recurring events. This is especially helpful if you want to add a daily or weekly appointment to your calendar. Recurring events can take place a specific number of times, repeat up to a specified date, or never end at\u00a0all.</p>\n<p>The DTSTART and DTEND or DURATION properties specify the first occurrence of the event and the RRULE parameter specifies the recursion scheme, for example, RRULE:FREQ=DAILY;COUNT=10 which means \u201c10 consecutive days\u201d. It is also possible to specify the exact dates when the meeting takes place using the RDATE property or remove unwanted occurrences from the recursion set using the EXDATE property (EXRULE has been deprecated). Make sure to check out this great <a href=\"https://jakubroztocil.github.io/rrule/\">rrule.js\u00a0demo</a>.</p>\n<p>A recurring event is stored as a single resource and all its instances share the same summary, description, etc. When you edit the event, the calendar client will usually ask you whether to edit only the single occurrence or all event instances.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*01Hyxv5CsglZpMN6inTMlw.png\"><figcaption>When editing or deleting a recurring event, Google Calendar will ask you which instances should be affected.</figcaption></figure><h3>CalDAV</h3>\n<p>In order to access the calendar from multiple devices, events can be stored on a remote calendar server. CalDAV (<a href=\"https://tools.ietf.org/html/rfc4791\">RFC 4791</a>, March 2008) is a protocol specification that defines how clients (for example Thunderbird or the calendar app on your phone) should interact with remote calendar servers (e.g. iCloud, Google Calendar, or your own instance).</p>\n<p>The idea behind CalDAV is to represent calendars as directories and events as iCalendar files. The protocol actually inherits from WebDAV, which is used for management and version control of files on the webserver. Each calendar user (or principal, according to CalDAV terminology) can have multiple calendars, which are identified by\u00a0URLs.</p>\n<p>An example CalDAV root URL:<br>http://example.com/path</p>\n<p>An example principal URL:<br>http://example.com/path<strong>/calendars/alice</strong></p>\n<p>An example calendar URL: <br>http://example.com/path<strong>/calendars/alice/work</strong></p>\n<p>An example event URL:<br>http://example.com/path<strong>/calendars/alice/work/meeting.ics</strong></p>\n<blockquote>Note: while many calendar clients use the same value (usually an <a href=\"https://en.wikipedia.org/wiki/Universally_unique_identifier\">UUID</a> to ensure uniqueness) both for CalDAV event URL and iCalendar UID property, this is not an obligation. The\u00a0.ics suffix is optional, but recommended as\u00a0well.</blockquote>\n<p>CalDAV uses the HTTP protocol to send XML requests with custom HTTP methods (such as MKCALENDAR or REPORT) and receive XML responses containing iCalendar data. For authentication, usually HTTP Basic or Digest authentication is used; sometimes OAuth\u00a02.0.</p>\n<p>A fully-implemented CalDAV server must support managing calendars, events, alarms, to-dos (tasks), and journal entries as well as implement an ACL (access control list) mechanism to check the user\u2019s permissions to access or modify the resource. Additionally, there are multiple optional extensions to the CalDAV protocol, including <a href=\"https://tools.ietf.org/html/rfc6638\">RFC 6638</a> (Scheduling Extensions to CalDAV), which defines how to handle events with organizers and multiple attendees, allowing them to accept or decline invites. Many calendar servers also support the CardDAV protocol (<a href=\"https://www.ietf.org/rfc/rfc6352.txt\">RFC 6352</a>) protocol for accessing and sharing contact data (address books) using vCard format (*.vcf\u00a0files).</p>\n<blockquote>Note: when the organizer deletes an event, it will not be removed from attendees\u2019 calendars\u200a\u2014\u200ainstead the status will change to \u201ccancelled\u201d.</blockquote>\n<p>There are many open-source calendar servers available, including <a href=\"https://sabre.io/baikal/\">Ba\u00efkal</a>, <a href=\"https://www.davical.org/\">DAViCal</a>, <a href=\"https://radicale.org/3.0.html\">Radicale</a>, and <a href=\"https://www.calendarserver.org/\">Calendar and Contacts Server</a>. The key difference is the set of implemented features as well as RFC compliance and compatibility with different clients, i.e. the calendar app on your device, <a href=\"https://www.thunderbird.net/pl/\">Thunderbird</a>, etc. Some calendar servers may try to fix the improper data or even fill the missing properties, while others may simply reject the\u00a0request.</p>\n<ul>\n<li><a href=\"https://sabre.io/dav/standards-support/\">https://sabre.io/dav/standards-support/</a></li>\n<li><a href=\"https://github.com/jelmer/xandikos#implemented-standards\">https://github.com/jelmer/xandikos#implemented-standards</a></li>\n</ul>\n<p>While the CalDAV protocol seems to cover all reasonable requirements for a single user, it certainly offers no administrative functionalities to aggregate data from multiple existing calendars within a single response. Other calendar providers, for instance Google Calendar, may provide custom APIs for additional functionalities.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*rGWbkXcqwF1MXwW01-5RMQ.png\"></figure><h3>Elixir CalDAV\u00a0Client</h3>\n<p>I was pretty surprised when I found out that there was no CalDAV client library for Elixir, so I wrote one. Currently, the library allows you\u00a0to:</p>\n<ul>\n<li>create, modify and delete the calendars,</li>\n<li>add, update and delete the events (with ETag and If-* headers support),</li>\n<li>get event from\u00a0URL,</li>\n<li>find an event by\u00a0UID,</li>\n<li>list all events happening or having an alarm within a specified time range<br>(with recurrence expansion enabled or disabled),</li>\n<li>retrieve events using custom XML requests,</li>\n<li>append custom HTTP headers via Tesla middlewares.</li>\n</ul>\n<p>Although the library implements only basic functionalities, it should be suitable for most of the applications. The library is <a href=\"https://hex.pm/packages/caldav_client\">published on Hex</a> and <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">available at Software Mansion Labs\u00a0GitHub</a>.</p>\n<p><a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">software-mansion-labs/elixir-caldav-client</a></p>\n<p>It is also worth mentioning that this library is only responsible for communication with the remote calendar server using CalDAV protocol and does not parse or serialize the iCalendar data. This approach allows the developers to use it in cooperation with any iCalendar parsing/serialization library (e.g. <a href=\"https://github.com/lpil/icalendar\">ICalendar</a> or <a href=\"https://github.com/kbrw/calibex\">Calibex</a>).</p>\n<p>To start with, you need to provide the server address as well as user credentials in the %CalDAVClient.Client struct:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*u0LBU4acJD9gN_bp__iRww.png\"></figure><p>You can generate the calendar URL using build_calendar_url/2 function:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zJl9_g-ibAmvrgU9kID2LA.png\"></figure><blockquote>Note: some calendar servers (including iCloud) use a custom scheme for calendar and event URLs. In such case, it is necessary to build the URL accordingly.</blockquote>\n<p>Then you may easily retrieve all events within a specified time range using get_events/4 function:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5U-NF3VAzU2l1QhAQKo6bA.png\"></figure><blockquote>Note: time ranges are start-inclusive and end-exclusive, so the results will not include any events starting at midnight on April 1st,\u00a02021.</blockquote>\n<p>You can also retrieve all instances of the events, i.e. with recurrence expansion enabled, by adding the expand: true option. Some calendar servers use naive implementations and some use more sophisticated algorithms, often natively implemented\u200a\u2014\u200athat\u2019s just an implementation detail, but certainly affects the overall performance and response\u00a0time.</p>\n<p>In order to create an event, just pass the event URL and iCalendar data to the CalDAVClient.Event.create/3 function. The following example uses the <a href=\"https://github.com/lpil/icalendar\">ICalendar</a> library to serialize an\u00a0event:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Rivz2ArVf01aNhfvVJjv_Q.png\"></figure><p>If you pass the etag option when modifying or deleting an event, the request will succeed only if the provided <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag\">ETag</a> matches the current version of the event, otherwise {:error,\u00a0:bad_etag} will be returned. This mechanism prevents simultaneous updates and ensures that the appropriate version of the event will be overwritten.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*yhodno96Q9kYB7hkaRp5IQ.png\"></figure><p>Check out <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client/blob/master/README.md\">README</a> and the <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client/tree/master/examples\">examples</a> in the GitHub repository.</p>\n<h3>Demo</h3>\n<p>The following example demonstrates how to connect to a CalDAV server (for instance iCloud Calendar) in Elixir to create and list the events from your calendar:</p>\n<p><a href=\"https://github.com/software-mansion-labs/elixir-caldav-client-demo\">software-mansion-labs/elixir-caldav-client-demo</a></p>\n<pre>git clone https://github.com/software-mansion-labs/elixir-caldav-client-demo &amp;&amp; cd elixir-caldav-client-demo</pre>\n<p>Let\u2019s start by getting the dependencies:</p>\n<pre>mix deps.get</pre>\n<p>Then create a configuration file from the template:</p>\n<pre>cp .env.example .env</pre>\n<p>Next, generate an app-specific password and fill the credentials in the\u00a0.env file as described in <a href=\"https://frightanic.com/apple-mac/thunderbird-icloud-calendar-sync/\">this tutorial</a>. Finally, launch the Elixir console with environmental variables fetched from the\u00a0.env\u00a0file:</p>\n<pre>set -a &amp;&amp; source .env &amp;&amp; set +a &amp;&amp; iex -S mix</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WQlnbocVGQxQmJc9ixv3oQ.png\"><figcaption>Elixir CalDAV Client library allows you to manage and list the events from your iCloud calendar.</figcaption></figure><p>Additionally, notice that on March 28th, 2021 the timezone changes from CET (<em>Central European Time</em>) to CEST (<em>Central European Summer Time</em>)\u200a\u2014\u200athat\u2019s when DST (<em>Daylight Saving Time</em>) comes into play\u200a\u2014\u200aand it\u2019s all handled automatically by the calendar\u00a0server.</p>\n<h3>Main takeaways</h3>\n<ul>\n<li>Always use DateTime instead of NaiveDateTime unless you really know what you\u2019re\u00a0doing.</li>\n<li>The iCalendar format allows representing recurring events thanks to the RRULE property.</li>\n<li>If you ever need to connect to a remote calendar server from your Elixir application, we recommend you the <a href=\"https://github.com/software-mansion-labs/elixir-caldav-client\">Elixir CalDAV Client</a>\u00a0library.</li>\n</ul>\n<h3>Elixir &amp; Open Source at Software\u00a0Mansion</h3>\n<p>Elixir has been an important focus area in Software Mansion for quite some time. We use this language in both commercial projects as well as to build and maintain one of our open source frameworks\u200a\u2014\u200aMembrane.</p>\n<p>Membrane is a multimedia processing framework that was created as an easy-to-use abstraction layer for assembling mostly server-side applications that have to consume, produce, or process multimedia streams. It\u2019s written in Elixir with the help of native code in\u00a0C.</p>\n<ul>\n<li><a href=\"https://www.membraneframework.org/\">Reliable &amp; scalable multimedia streaming</a></li>\n<li><a href=\"https://swmansion.com/community/open-source/\">Open Source - Software Mansion</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=13be601572eb\" width=\"1\" height=\"1\" alt=\"\"><hr>\n<p><a href=\"https://blog.swmansion.com/icalendar-caldav-elixir-13be601572eb\">iCalendar, CalDAV &amp; Elixir</a> was originally published in <a href=\"https://blog.swmansion.com/\">Software Mansion</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>\n",
            "enclosure": {},
            "categories": [
                "caldav",
                "icalendar",
                "elixir",
                "framework",
                "open-source"
            ]
        }
    ]
}